{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_NER_2.1.attempt_BERT_not_working.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainvo/DeepLearning_NER/blob/master/DL_NER_2_1_attempt_BERT_not_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hTBsYI1tLeVk"
      },
      "source": [
        "# Deep Learning NER task\n",
        "\n",
        "Tatjana Cucic and Sanna Volanen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T2GevEzfPP2",
        "colab_type": "text"
      },
      "source": [
        "https://spacy.io/api/annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O5MwAmUALZ4V"
      },
      "source": [
        "# Milestones\n",
        "\n",
        "## 1.1 Predicting word labels independently\n",
        "\n",
        "* The first part is to train a classifier which assigns a label for each given input word independently. \n",
        "* Evaluate the results on token level and entity level. \n",
        "* Report your results with different network hyperparameters. \n",
        "* Also discuss whether the token level accuracy is a reasonable metric.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Q3HiGQgMU5L",
        "outputId": "9896986e-5834-41a7-940f-6fa9e45b8a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "# Training data: Used for training the model\n",
        "!wget https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/train.tsv\n",
        "\n",
        "# Development/ validation data: Used for testing different model parameters, for example level of regularization needed\n",
        "!wget https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/dev.tsv\n",
        "\n",
        "# Test data: Never touched during training / model development, used for evaluating the final model\n",
        "!wget https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/test.tsv\n",
        "\n",
        "import sys \n",
        "import csv\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-10 16:28:24--  https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17252156 (16M) [text/plain]\n",
            "Saving to: ‘train.tsv’\n",
            "\n",
            "\rtrain.tsv             0%[                    ]       0  --.-KB/s               \rtrain.tsv            23%[===>                ]   3.87M  19.4MB/s               \rtrain.tsv           100%[===================>]  16.45M  42.6MB/s    in 0.4s    \n",
            "\n",
            "2020-05-10 16:28:25 (42.6 MB/s) - ‘train.tsv’ saved [17252156/17252156]\n",
            "\n",
            "--2020-05-10 16:28:28--  https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/dev.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2419425 (2.3M) [text/plain]\n",
            "Saving to: ‘dev.tsv’\n",
            "\n",
            "dev.tsv             100%[===================>]   2.31M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-10 16:28:29 (22.8 MB/s) - ‘dev.tsv’ saved [2419425/2419425]\n",
            "\n",
            "--2020-05-10 16:28:30--  https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/test.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1788466 (1.7M) [text/plain]\n",
            "Saving to: ‘test.tsv’\n",
            "\n",
            "test.tsv            100%[===================>]   1.71M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-05-10 16:28:31 (20.7 MB/s) - ‘test.tsv’ saved [1788466/1788466]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zOOHEYpiMzFp",
        "outputId": "1238827e-4476-4f2e-bc4d-2b33bd585335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "from collections import namedtuple\n",
        "OneWord=namedtuple(\"OneWord\",[\"word\",\"entity_label\"])\n",
        "\n",
        "def read_ontonotes(tsv_file):\n",
        "  #\"\"\"Yield complete sentences\"\"\"\n",
        "    current_sentence=[] # list of (word,label) tuples\n",
        "    with open(tsv_file) as f:\n",
        "        tsvreader = csv.reader(f, delimiter= '\\t')\n",
        "        for line in tsvreader:\n",
        "            #print(line)\n",
        "            if not line: #sentence break\n",
        "                if current_sentence: #if we gathered a sentence, we should yield it, because a new starts\n",
        "                    yield current_sentence #much like return, but continues past this line once the element has been consumed\n",
        "                    current_sentence=[] #...and start a new one\n",
        "                continue\n",
        "            #if we made it here, we are on a normal line\n",
        "            columns=[line[0], line[1]] #an actual word line\n",
        "            assert len(columns)==2 #we should have four columns, looking at the data\n",
        "            current_sentence.append(OneWord(*columns)) #shorthand for looping over columns\n",
        "        else: #for ... else -> the else part is executed once, when \"for\" runs out of elements\n",
        "            if current_sentence: #yield also the last one!\n",
        "                yield current_sentence\n",
        "\n",
        "#read the data in as sentences\n",
        "sentences_train=list(read_ontonotes(\"train.tsv\"))\n",
        "sentences_dev=list(read_ontonotes(\"dev.tsv\"))\n",
        "sentences_test = list(read_ontonotes(\"test.tsv\"))\n",
        "\n",
        "print(type(sentences_test))\n",
        "\n",
        "print(\"First three sentences\")\n",
        "for sent in sentences_train[:3]:\n",
        "    print(sent)\n",
        "print(len(sentences_train))\n",
        "print('---------------------------------------------')\n",
        "print(\"First three sentences\")\n",
        "for sent in sentences_dev[:3]:\n",
        "    print(sent)\n",
        "print(len(sentences_dev))\n",
        "print('---------------------------------------------')\n",
        "print(\"First three sentences\")\n",
        "for sent in sentences_test[:3]:\n",
        "    print(sent)\n",
        "print(len(sentences_test))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "First three sentences\n",
            "[OneWord(word='Big', entity_label='O'), OneWord(word='Managers', entity_label='O'), OneWord(word='on', entity_label='O'), OneWord(word='Campus', entity_label='O')]\n",
            "[OneWord(word='In', entity_label='O'), OneWord(word='recent', entity_label='B-DATE'), OneWord(word='years', entity_label='I-DATE'), OneWord(word=',', entity_label='O'), OneWord(word='advanced', entity_label='O'), OneWord(word='education', entity_label='O'), OneWord(word='for', entity_label='O'), OneWord(word='professionals', entity_label='O'), OneWord(word='has', entity_label='O'), OneWord(word='become', entity_label='O'), OneWord(word='a', entity_label='O'), OneWord(word='hot', entity_label='O'), OneWord(word='topic', entity_label='O'), OneWord(word='in', entity_label='O'), OneWord(word='the', entity_label='O'), OneWord(word='business', entity_label='O'), OneWord(word='community', entity_label='O'), OneWord(word='.', entity_label='O')]\n",
            "[OneWord(word='With', entity_label='O'), OneWord(word='this', entity_label='O'), OneWord(word='trend', entity_label='O'), OneWord(word=',', entity_label='O'), OneWord(word='suddenly', entity_label='O'), OneWord(word='the', entity_label='O'), OneWord(word='mature', entity_label='O'), OneWord(word='faces', entity_label='O'), OneWord(word='of', entity_label='O'), OneWord(word='managers', entity_label='O'), OneWord(word='boasting', entity_label='O'), OneWord(word='an', entity_label='O'), OneWord(word='average', entity_label='O'), OneWord(word='of', entity_label='O'), OneWord(word='over', entity_label='O'), OneWord(word='ten', entity_label='B-DATE'), OneWord(word='years', entity_label='I-DATE'), OneWord(word='of', entity_label='O'), OneWord(word='professional', entity_label='O'), OneWord(word='experience', entity_label='O'), OneWord(word='have', entity_label='O'), OneWord(word='flooded', entity_label='O'), OneWord(word='in', entity_label='O'), OneWord(word='among', entity_label='O'), OneWord(word='the', entity_label='O'), OneWord(word='young', entity_label='O'), OneWord(word='people', entity_label='O'), OneWord(word='populating', entity_label='O'), OneWord(word='university', entity_label='O'), OneWord(word='campuses', entity_label='O'), OneWord(word='.', entity_label='O')]\n",
            "66818\n",
            "---------------------------------------------\n",
            "First three sentences\n",
            "[OneWord(word='President', entity_label='B-WORK_OF_ART'), OneWord(word='Chen', entity_label='I-WORK_OF_ART'), OneWord(word='Travels', entity_label='I-WORK_OF_ART'), OneWord(word='Abroad', entity_label='I-WORK_OF_ART')]\n",
            "[OneWord(word='(', entity_label='O'), OneWord(word='Chang', entity_label='B-PERSON'), OneWord(word='Chiung', entity_label='I-PERSON'), OneWord(word='-', entity_label='I-PERSON'), OneWord(word='fang', entity_label='I-PERSON'), OneWord(word='/', entity_label='O'), OneWord(word='tr.', entity_label='O'), OneWord(word='by', entity_label='O'), OneWord(word='David', entity_label='B-PERSON'), OneWord(word='Mayer', entity_label='I-PERSON'), OneWord(word=')', entity_label='O')]\n",
            "[OneWord(word='President', entity_label='O'), OneWord(word='Chen', entity_label='B-PERSON'), OneWord(word='Shui', entity_label='I-PERSON'), OneWord(word='-', entity_label='I-PERSON'), OneWord(word='bian', entity_label='I-PERSON'), OneWord(word='visited', entity_label='O'), OneWord(word='the', entity_label='B-FAC'), OneWord(word='Nicaraguan', entity_label='I-FAC'), OneWord(word='National', entity_label='I-FAC'), OneWord(word='Assembly', entity_label='I-FAC'), OneWord(word='on', entity_label='O'), OneWord(word='August', entity_label='B-DATE'), OneWord(word='17', entity_label='I-DATE'), OneWord(word=',', entity_label='O'), OneWord(word='where', entity_label='O'), OneWord(word='he', entity_label='O'), OneWord(word='received', entity_label='O'), OneWord(word='a', entity_label='O'), OneWord(word='medal', entity_label='O'), OneWord(word='from', entity_label='O'), OneWord(word='the', entity_label='O'), OneWord(word='president', entity_label='O'), OneWord(word='of', entity_label='O'), OneWord(word='the', entity_label='O'), OneWord(word='assembly', entity_label='O'), OneWord(word=',', entity_label='O'), OneWord(word='Ivan', entity_label='B-PERSON'), OneWord(word='Escobar', entity_label='I-PERSON'), OneWord(word='Fornos', entity_label='I-PERSON'), OneWord(word='.', entity_label='O')]\n",
            "11612\n",
            "---------------------------------------------\n",
            "First three sentences\n",
            "[OneWord(word='Powerful', entity_label='B-WORK_OF_ART'), OneWord(word='Tools', entity_label='I-WORK_OF_ART'), OneWord(word='for', entity_label='I-WORK_OF_ART'), OneWord(word='Biotechnology', entity_label='I-WORK_OF_ART'), OneWord(word='-', entity_label='I-WORK_OF_ART'), OneWord(word='Biochips', entity_label='I-WORK_OF_ART')]\n",
            "[OneWord(word='(', entity_label='O'), OneWord(word='Chang', entity_label='B-PERSON'), OneWord(word='Chiung', entity_label='I-PERSON'), OneWord(word='-', entity_label='I-PERSON'), OneWord(word='fang', entity_label='I-PERSON'), OneWord(word='/', entity_label='O'), OneWord(word='photos', entity_label='O'), OneWord(word='by', entity_label='O'), OneWord(word='Hsueh', entity_label='B-PERSON'), OneWord(word='Chi', entity_label='I-PERSON'), OneWord(word='-', entity_label='I-PERSON'), OneWord(word='kuang', entity_label='I-PERSON'), OneWord(word='/', entity_label='O'), OneWord(word='tr.', entity_label='O'), OneWord(word='by', entity_label='O'), OneWord(word='Robert', entity_label='B-PERSON'), OneWord(word='Taylor', entity_label='I-PERSON'), OneWord(word=')', entity_label='O')]\n",
            "[OneWord(word='The', entity_label='O'), OneWord(word='enterovirus', entity_label='O'), OneWord(word='detection', entity_label='O'), OneWord(word='biochip', entity_label='O'), OneWord(word='developed', entity_label='O'), OneWord(word='by', entity_label='O'), OneWord(word='DR.', entity_label='B-ORG'), OneWord(word='Chip', entity_label='I-ORG'), OneWord(word='Biotechnology', entity_label='I-ORG'), OneWord(word='takes', entity_label='O'), OneWord(word='only', entity_label='B-TIME'), OneWord(word='six', entity_label='I-TIME'), OneWord(word='hours', entity_label='I-TIME'), OneWord(word='to', entity_label='O'), OneWord(word='give', entity_label='O'), OneWord(word='hospitals', entity_label='O'), OneWord(word='the', entity_label='O'), OneWord(word='answer', entity_label='O'), OneWord(word='to', entity_label='O'), OneWord(word='whether', entity_label='O'), OneWord(word='a', entity_label='O'), OneWord(word='sample', entity_label='O'), OneWord(word='contains', entity_label='O'), OneWord(word='enterovirus', entity_label='O'), OneWord(word=',', entity_label='O'), OneWord(word='and', entity_label='O'), OneWord(word='if', entity_label='O'), OneWord(word='it', entity_label='O'), OneWord(word='is', entity_label='O'), OneWord(word='the', entity_label='O'), OneWord(word='deadly', entity_label='O'), OneWord(word='strain', entity_label='O'), OneWord(word='Entero', entity_label='O'), OneWord(word='71', entity_label='O'), OneWord(word='.', entity_label='O')]\n",
            "9751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cZHhXzVTQA_P",
        "colab": {}
      },
      "source": [
        "# shape into dicts per sentence\n",
        "\n",
        "def reshape_sent2dicts(f):\n",
        "    data_dict = []\n",
        "    for line in f:\n",
        "        sent_text= [] \n",
        "        sent_tags = []\n",
        "        for OneWord in line:\n",
        "            #print(OneWord)\n",
        "            sent_text.append(OneWord.word)\n",
        "            sent_tags.append(OneWord.entity_label)\n",
        "        sent_dict = {'text':sent_text,'tags':sent_tags }\n",
        "        #print(sent_dict)\n",
        "        data_dict.append(sent_dict)\n",
        "    return data_dict\n",
        "\n",
        "train_data = list(reshape_sent2dicts(sentences_train[:30000]))\n",
        "\n",
        "dev_data = list(reshape_sent2dicts(sentences_dev))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VpYBQMbcQGBi",
        "outputId": "e09cbc74-3ea5-4a46-fc8f-8a784589ce38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import random\n",
        "import numpy\n",
        "\n",
        "random.seed(123)\n",
        "random.shuffle(train_data)\n",
        "print(type(train_data))\n",
        "print(type(train_data[0]))\n",
        "\n",
        "train_texts=[i[\"text\"] for i in train_data]\n",
        "train_labels=[i[\"tags\"] for i in train_data]\n",
        "\n",
        "print(type(train_texts))\n",
        "print(type(train_texts[0]))\n",
        "\n",
        "print('Text: ', train_texts[0])\n",
        "print('Label: ', train_labels[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'dict'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "Text:  ['Sharon', 'Repudiates', 'the', 'Road', 'Map', '.']\n",
            "Label:  ['O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNQQRw0YO-Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## same for validation/dev data\n",
        "dev_texts=[i[\"text\"] for i in dev_data]\n",
        "dev_labels=[i[\"tags\"] for i in dev_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICn08fOgbyXl",
        "colab_type": "code",
        "outputId": "fdd9cd78-a33f-4fd9-9168-d8fff01c7c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Load pretrained embeddings\n",
        "!wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-10 16:28:35--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4a8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  57.0MB/s    in 11s     \n",
            "\n",
            "2020-05-10 16:28:47 (56.7 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFv2qclTbyXp",
        "colab_type": "code",
        "outputId": "c03d60a6-293c-41da-f9f4-c46c31e08973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Give -n argument so that a possible existing file isn't overwritten \n",
        "!unzip -n wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx_C5ii8byXt",
        "colab_type": "code",
        "outputId": "cd13e790-e0e0-4995-dcb6-aa156d75c2fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "vector_model = KeyedVectors.load_word2vec_format(\"wiki-news-300d-1M.vec\", binary=False, limit=50000)\n",
        "\n",
        "\n",
        "# sort based on the index to make sure they are in the correct order\n",
        "words = [k for k, v in sorted(vector_model.vocab.items(), key=lambda x: x[1].index)]\n",
        "print(\"Words from embedding model:\", len(words))\n",
        "print(\"First 50 words:\", words[:50])\n",
        "\n",
        "# Normalize the vectors to unit length\n",
        "print(\"Before normalization:\", vector_model.get_vector(\"in\")[:10])\n",
        "vector_model.init_sims(replace=True)\n",
        "print(\"After normalization:\", vector_model.get_vector(\"in\")[:10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Words from embedding model: 50000\n",
            "First 50 words: [',', 'the', '.', 'and', 'of', 'to', 'in', 'a', '\"', ':', ')', 'that', '(', 'is', 'for', 'on', '*', 'with', 'as', 'it', 'The', 'or', 'was', \"'\", \"'s\", 'by', 'from', 'at', 'I', 'this', 'you', '/', 'are', '=', 'not', '-', 'have', '?', 'be', 'which', ';', 'all', 'his', 'has', 'one', 'their', 'about', 'but', 'an', '|']\n",
            "Before normalization: [-0.0234 -0.0268 -0.0838  0.0386 -0.0321  0.0628  0.0281 -0.0252  0.0269\n",
            " -0.0063]\n",
            "After normalization: [-0.0163762  -0.01875564 -0.05864638  0.02701372 -0.02246478  0.04394979\n",
            "  0.01966543 -0.0176359   0.01882563 -0.00440898]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkdgjgOlbyXx",
        "colab_type": "code",
        "outputId": "a3f6611f-be2e-498c-daa9-5d681bdb7a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Build vocabulary mappings\n",
        "\n",
        "# Zero is used for padding in Keras, prevent using it for a normal word.\n",
        "# Also reserve an index for out-of-vocabulary items.\n",
        "vocabulary={\n",
        "    \"<PAD>\": 0,\n",
        "    \"<OOV>\": 1\n",
        "}\n",
        "\n",
        "for word in words: # These are words from the word2vec model\n",
        "    vocabulary.setdefault(word, len(vocabulary))\n",
        "\n",
        "print(\"Words in vocabulary:\",len(vocabulary))\n",
        "inv_vocabulary = { value: key for key, value in vocabulary.items() } # invert the dictionary\n",
        "\n",
        "\n",
        "# Embedding matrix\n",
        "def load_pretrained_embeddings(vocab, embedding_model):\n",
        "    \"\"\" vocab: vocabulary from our data vectorizer, embedding_model: model loaded with gensim \"\"\"\n",
        "    pretrained_embeddings = numpy.random.uniform(low=-0.05, high=0.05, size=(len(vocab)-1,embedding_model.vectors.shape[1]))\n",
        "    pretrained_embeddings = numpy.vstack((numpy.zeros(shape=(1,embedding_model.vectors.shape[1])), pretrained_embeddings))\n",
        "    found=0\n",
        "    for word,idx in vocab.items():\n",
        "        if word in embedding_model.vocab:\n",
        "            pretrained_embeddings[idx]=embedding_model.get_vector(word)\n",
        "            found+=1\n",
        "            \n",
        "    print(\"Found pretrained vectors for {found} words.\".format(found=found))\n",
        "    return pretrained_embeddings\n",
        "\n",
        "pretrained=load_pretrained_embeddings(vocabulary, vector_model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words in vocabulary: 50002\n",
            "Found pretrained vectors for 50000 words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGaojUBhbyX2",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M9Ox5_ObyX3",
        "colab_type": "code",
        "outputId": "b797f33f-b4b7-4f4a-cd39-b9832e4bdfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "#Labels\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "# Label mappings\n",
        "# 1) gather a set of unique labels\n",
        "label_set = set()\n",
        "for sentence_labels in train_labels: #loops over sentences \n",
        "    for label in sentence_labels: #loops over labels in one sentence\n",
        "        label_set.add(label)\n",
        "\n",
        "# 2) index these\n",
        "label_map = {}\n",
        "for index, label in enumerate(label_set):\n",
        "    label_map[label]=index\n",
        "    \n",
        "pprint(label_map)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-CARDINAL': 12,\n",
            " 'B-DATE': 20,\n",
            " 'B-EVENT': 16,\n",
            " 'B-FAC': 35,\n",
            " 'B-GPE': 0,\n",
            " 'B-LANGUAGE': 36,\n",
            " 'B-LAW': 6,\n",
            " 'B-LOC': 19,\n",
            " 'B-MONEY': 32,\n",
            " 'B-NORP': 11,\n",
            " 'B-ORDINAL': 25,\n",
            " 'B-ORG': 21,\n",
            " 'B-PERCENT': 7,\n",
            " 'B-PERSON': 10,\n",
            " 'B-PRODUCT': 31,\n",
            " 'B-QUANTITY': 8,\n",
            " 'B-TIME': 24,\n",
            " 'B-WORK_OF_ART': 34,\n",
            " 'I-CARDINAL': 5,\n",
            " 'I-DATE': 15,\n",
            " 'I-EVENT': 14,\n",
            " 'I-FAC': 28,\n",
            " 'I-GPE': 9,\n",
            " 'I-LANGUAGE': 3,\n",
            " 'I-LAW': 27,\n",
            " 'I-LOC': 23,\n",
            " 'I-MONEY': 30,\n",
            " 'I-NORP': 26,\n",
            " 'I-ORDINAL': 1,\n",
            " 'I-ORG': 33,\n",
            " 'I-PERCENT': 18,\n",
            " 'I-PERSON': 4,\n",
            " 'I-PRODUCT': 13,\n",
            " 'I-QUANTITY': 22,\n",
            " 'I-TIME': 17,\n",
            " 'I-WORK_OF_ART': 29,\n",
            " 'O': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8k8DshceEaI",
        "colab_type": "code",
        "outputId": "67b4788a-af8a-4f76-ca46-5c8fea0d22f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vectorize the labels\n",
        "def label_vectorizer(train_labels,label_map):\n",
        "    vectorized_labels = []\n",
        "    for label in train_labels:\n",
        "        vectorized_example_label = []\n",
        "        for token in label:\n",
        "            vectorized_example_label.append(label_map[token])\n",
        "        vectorized_labels.append(vectorized_example_label)\n",
        "    vectorized_labels = numpy.array(vectorized_labels)\n",
        "    return vectorized_labels\n",
        "        \n",
        "\n",
        "vectorized_labels = label_vectorizer(train_labels,label_map)\n",
        "validation_vectorized_labels = label_vectorizer(dev_labels,label_map)\n",
        "\n",
        "pprint(vectorized_labels[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUtqLdCMPf3X",
        "colab_type": "code",
        "outputId": "1a9446a9-f435-4f3a-c772-6cdeedb4b065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## vectorization of the texts\n",
        "def text_vectorizer(vocab, train_texts):\n",
        "    vectorized_data = [] # turn text into numbers based on our vocabulary mapping\n",
        "    sentence_lengths = [] # Number of tokens in each sentence\n",
        "    \n",
        "    for i, one_example in enumerate(train_texts):\n",
        "        vectorized_example = []\n",
        "        for word in one_example:\n",
        "            vectorized_example.append(vocab.get(word, 1)) # 1 is our index for out-of-vocabulary tokens\n",
        "\n",
        "        vectorized_data.append(vectorized_example)     \n",
        "        sentence_lengths.append(len(one_example))\n",
        "        \n",
        "    vectorized_data = numpy.array(vectorized_data) # turn python list into numpy array\n",
        "    \n",
        "    return vectorized_data, sentence_lengths\n",
        "\n",
        "vectorized_data, lengths=text_vectorizer(vocabulary, train_texts)\n",
        "validation_vectorized_data, validation_lengths=text_vectorizer(vocabulary, dev_texts)\n",
        "\n",
        "pprint(train_texts[0])\n",
        "pprint(vectorized_data[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sharon', 'Repudiates', 'the', 'Road', 'Map', '.']\n",
            "[8346, 1, 3, 1685, 8936, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e6FH5F1QGrq",
        "colab_type": "code",
        "outputId": "125cf363-1d21-4b41-cff1-a3060933ea39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# padding for tensor\n",
        "import tensorflow as tf\n",
        "### Only needed for me, not to block the whole GPU, you don't need this stuff\n",
        "#from keras.backend.tensorflow_backend import set_session\n",
        "#config = tf.ConfigProto()\n",
        "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "#set_session(tf.Session(config=config))\n",
        "### ---end of weird stuff\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "print(\"Old shape:\", vectorized_data.shape)\n",
        "vectorized_data_padded=pad_sequences(vectorized_data, padding='post', maxlen=max(lengths))\n",
        "print(\"New shape:\", vectorized_data_padded.shape)\n",
        "print(\"First example:\")\n",
        "print( vectorized_data_padded[0])\n",
        "# Even with the sparse output format, the shape has to be similar to the one-hot encoding\n",
        "vectorized_labels_padded=numpy.expand_dims(pad_sequences(vectorized_labels, padding='post', maxlen=max(lengths)), -1)\n",
        "print(\"Padded labels shape:\", vectorized_labels_padded.shape)\n",
        "pprint(label_map)\n",
        "print(\"First example labels:\")\n",
        "pprint(vectorized_labels_padded[0])\n",
        "\n",
        "weights = numpy.copy(vectorized_data_padded)\n",
        "weights[weights > 0] = 1\n",
        "print(\"First weight vector:\")\n",
        "print( weights[0])\n",
        "\n",
        "# Same stuff for the validation data\n",
        "validation_vectorized_data_padded=pad_sequences(validation_vectorized_data, padding='post', maxlen=max(lengths))\n",
        "validation_vectorized_labels_padded=numpy.expand_dims(pad_sequences(validation_vectorized_labels, padding='post',maxlen=max(lengths)), -1)\n",
        "validation_weights = numpy.copy(validation_vectorized_data_padded)\n",
        "validation_weights[validation_weights > 0] = 1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Old shape: (30000,)\n",
            "New shape: (30000, 561)\n",
            "First example:\n",
            "[8346    1    3 1685 8936    4    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0]\n",
            "Padded labels shape: (30000, 561, 1)\n",
            "{'B-CARDINAL': 12,\n",
            " 'B-DATE': 20,\n",
            " 'B-EVENT': 16,\n",
            " 'B-FAC': 35,\n",
            " 'B-GPE': 0,\n",
            " 'B-LANGUAGE': 36,\n",
            " 'B-LAW': 6,\n",
            " 'B-LOC': 19,\n",
            " 'B-MONEY': 32,\n",
            " 'B-NORP': 11,\n",
            " 'B-ORDINAL': 25,\n",
            " 'B-ORG': 21,\n",
            " 'B-PERCENT': 7,\n",
            " 'B-PERSON': 10,\n",
            " 'B-PRODUCT': 31,\n",
            " 'B-QUANTITY': 8,\n",
            " 'B-TIME': 24,\n",
            " 'B-WORK_OF_ART': 34,\n",
            " 'I-CARDINAL': 5,\n",
            " 'I-DATE': 15,\n",
            " 'I-EVENT': 14,\n",
            " 'I-FAC': 28,\n",
            " 'I-GPE': 9,\n",
            " 'I-LANGUAGE': 3,\n",
            " 'I-LAW': 27,\n",
            " 'I-LOC': 23,\n",
            " 'I-MONEY': 30,\n",
            " 'I-NORP': 26,\n",
            " 'I-ORDINAL': 1,\n",
            " 'I-ORG': 33,\n",
            " 'I-PERCENT': 18,\n",
            " 'I-PERSON': 4,\n",
            " 'I-PRODUCT': 13,\n",
            " 'I-QUANTITY': 22,\n",
            " 'I-TIME': 17,\n",
            " 'I-WORK_OF_ART': 29,\n",
            " 'O': 2}\n",
            "First example labels:\n",
            "array([[2],\n",
            "       [2],\n",
            "       [2],\n",
            "       [2],\n",
            "       [2],\n",
            "       [2],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32)\n",
            "First weight vector:\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhAOVAbBTRAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation function\n",
        "import keras\n",
        "\n",
        "def _convert_to_entities(input_sequence):\n",
        "    \"\"\"\n",
        "    Reads a sequence of tags and converts them into a set of entities.\n",
        "    \"\"\"\n",
        "    entities = []\n",
        "    current_entity = []\n",
        "    previous_tag = label_map['O']\n",
        "    for i, tag in enumerate(input_sequence):\n",
        "        if tag != previous_tag and tag != label_map['O']: # New entity starts\n",
        "            if len(current_entity) > 0:\n",
        "                entities.append(current_entity)\n",
        "                current_entity = []\n",
        "            current_entity.append((tag, i))\n",
        "        elif tag == label_map['O']: # Entity has ended\n",
        "            if len(current_entity) > 0:\n",
        "                entities.append(current_entity)\n",
        "                current_entity = []\n",
        "        elif tag == previous_tag: # Current entity continues\n",
        "            current_entity.append((tag, i))\n",
        "        previous_tag = tag\n",
        "    \n",
        "    # Add the last entity to our entity list if the sentences ends with an entity\n",
        "    if len(current_entity) > 0:\n",
        "        entities.append(current_entity)\n",
        "    \n",
        "    entity_offsets = set()\n",
        "    \n",
        "    for e in entities:\n",
        "        entity_offsets.add((e[0][0], e[0][1], e[-1][1]+1))\n",
        "    return entity_offsets\n",
        "\n",
        "def _entity_level_PRF(predictions, gold, lengths):\n",
        "    pred_entities = [_convert_to_entities(labels[:lengths[i]]) for i, labels in enumerate(predictions)]\n",
        "    gold_entities = [_convert_to_entities(labels[:lengths[i], 0]) for i, labels in enumerate(gold)]\n",
        "    \n",
        "    tp = sum([len(pe.intersection(gold_entities[i])) for i, pe in enumerate(pred_entities)])\n",
        "    pred_count = sum([len(e) for e in pred_entities])\n",
        "    \n",
        "    try:\n",
        "        precision = tp / pred_count # tp / (tp+np)\n",
        "        recall = tp / sum([len(e) for e in gold_entities])\n",
        "        fscore = 2 * precision * recall / (precision + recall)\n",
        "    except Exception as e:\n",
        "        precision, recall, fscore = 0.0, 0.0, 0.0\n",
        "    print('\\nPrecision/Recall/F-score: %s / %s / %s' % (precision, recall, fscore))\n",
        "    return precision, recall, fscore             \n",
        "\n",
        "def evaluate(predictions, gold, lengths):\n",
        "    precision, recall, fscore = _entity_level_PRF(predictions, gold, lengths)\n",
        "    return precision, recall, fscore\n",
        "\n",
        "class EvaluateEntities(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.precision = []\n",
        "        self.recall = []\n",
        "        self.fscore = []\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        pred = numpy.argmax(self.model.predict(validation_vectorized_data_padded), axis=-1)\n",
        "        evaluation_parameters=evaluate(pred, validation_vectorized_labels_padded, validation_lengths)\n",
        "        self.precision.append(evaluation_parameters[0])\n",
        "        self.recall.append(evaluation_parameters[1])\n",
        "        self.fscore.append(evaluation_parameters[2])\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1ydCexfTg5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Embedding, Activation, TimeDistributed\n",
        "from keras.optimizers import SGD, Adam\n",
        "\n",
        "example_count, sequence_len = vectorized_data_padded.shape\n",
        "class_count = len(label_set)\n",
        "hidden_size = 100\n",
        "\n",
        "vector_size= pretrained.shape[1]\n",
        "\n",
        "def build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained):\n",
        "    inp=Input(shape=(sequence_len,))\n",
        "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=True, trainable=False, weights=[pretrained])(inp)\n",
        "    hidden = TimeDistributed(Dense(hidden_size, activation=\"sigmoid\"))(embeddings) # We change this activation function\n",
        "    outp = TimeDistributed(Dense(class_count, activation=\"softmax\"))(hidden)\n",
        "    return Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "model = build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oUO3GLfTrl3",
        "colab_type": "code",
        "outputId": "983a888d-6e2e-443d-9e91-20bf9c55ec60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 561)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 561, 300)          15000600  \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 561, 100)          30100     \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 561, 37)           3737      \n",
            "=================================================================\n",
            "Total params: 15,034,437\n",
            "Trainable params: 33,837\n",
            "Non-trainable params: 15,000,600\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIPQrLXUVrWr",
        "colab_type": "code",
        "outputId": "a36ebe39-36a9-45b1-9f2c-632216cd14c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model\n",
        "optimizer=Adam(lr=0.007) # define the learning rate\n",
        "model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
        "evaluation_function=EvaluateEntities()\n",
        "\n",
        "# train\n",
        "vanilla_hist=model.fit(vectorized_data_padded,vectorized_labels_padded, sample_weight=weights, batch_size=100,verbose=2,epochs=20, callbacks=[evaluation_function])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " - 4s - loss: 0.0129\n",
            "\n",
            "Precision/Recall/F-score: 0.4797613975287601 / 0.1628167588475581 / 0.24312434212301962\n",
            "Epoch 2/20\n",
            " - 2s - loss: 0.0081\n",
            "\n",
            "Precision/Recall/F-score: 0.4788386153743937 / 0.26052850377760906 / 0.3374537622325232\n",
            "Epoch 3/20\n",
            " - 2s - loss: 0.0075\n",
            "\n",
            "Precision/Recall/F-score: 0.5090306652806653 / 0.28323030763113183 / 0.36395308326559056\n",
            "Epoch 4/20\n",
            " - 2s - loss: 0.0072\n",
            "\n",
            "Precision/Recall/F-score: 0.49349069229833314 / 0.29324368289773345 / 0.367882814448652\n",
            "Epoch 5/20\n",
            " - 2s - loss: 0.0071\n",
            "\n",
            "Precision/Recall/F-score: 0.4983930778739184 / 0.29150851317644505 / 0.36785803891157076\n",
            "Epoch 6/20\n",
            " - 2s - loss: 0.0070\n",
            "\n",
            "Precision/Recall/F-score: 0.49840406048872377 / 0.3443227415681596 / 0.4072775473553683\n",
            "Epoch 7/20\n",
            " - 2s - loss: 0.0069\n",
            "\n",
            "Precision/Recall/F-score: 0.48766979537107213 / 0.30238947330369087 / 0.3733041770796145\n",
            "Epoch 8/20\n",
            " - 2s - loss: 0.0068\n",
            "\n",
            "Precision/Recall/F-score: 0.48152112676056336 / 0.30896865849690924 / 0.3764120406051131\n",
            "Epoch 9/20\n",
            " - 2s - loss: 0.0068\n",
            "\n",
            "Precision/Recall/F-score: 0.48135538261997407 / 0.32198243140657196 / 0.38586002989148094\n",
            "Epoch 10/20\n",
            " - 2s - loss: 0.0068\n",
            "\n",
            "Precision/Recall/F-score: 0.4930400890868597 / 0.3201026642085096 / 0.3881813997325911\n",
            "Epoch 11/20\n",
            " - 2s - loss: 0.0067\n",
            "\n",
            "Precision/Recall/F-score: 0.4915774207942883 / 0.31858439070238226 / 0.38661139259941657\n",
            "Epoch 12/20\n",
            " - 2s - loss: 0.0067\n",
            "\n",
            "Precision/Recall/F-score: 0.4945210321668434 / 0.3034378050103026 / 0.3761005443914242\n",
            "Epoch 13/20\n",
            " - 2s - loss: 0.0066\n",
            "\n",
            "Precision/Recall/F-score: 0.5045060759346474 / 0.31366807649206524 / 0.38683072533547325\n",
            "Epoch 14/20\n",
            " - 2s - loss: 0.0066\n",
            "\n",
            "Precision/Recall/F-score: 0.48227936066712995 / 0.3261396088638253 / 0.38913090360146646\n",
            "Epoch 15/20\n",
            " - 2s - loss: 0.0066\n",
            "\n",
            "Precision/Recall/F-score: 0.5164998647552069 / 0.27610888190001087 / 0.359850180207769\n",
            "Epoch 16/20\n",
            " - 2s - loss: 0.0066\n",
            "\n",
            "Precision/Recall/F-score: 0.4944754288119541 / 0.33973177168058416 / 0.40275129100687823\n",
            "Epoch 17/20\n",
            " - 2s - loss: 0.0065\n",
            "\n",
            "Precision/Recall/F-score: 0.4880952380952381 / 0.3142103170299678 / 0.3823096039233797\n",
            "Epoch 18/20\n",
            " - 2s - loss: 0.0065\n",
            "\n",
            "Precision/Recall/F-score: 0.47430138264978705 / 0.29389437154321657 / 0.36291402553343455\n",
            "Epoch 19/20\n",
            " - 2s - loss: 0.0065\n",
            "\n",
            "Precision/Recall/F-score: 0.48762955533266467 / 0.31634312981238477 / 0.3837400513056633\n",
            "Epoch 20/20\n",
            " - 2s - loss: 0.0065\n",
            "\n",
            "Precision/Recall/F-score: 0.47938512215207246 / 0.31565629179770816 / 0.3806617550895855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bah0URSVV5GP",
        "colab_type": "code",
        "outputId": "a3122643-d33d-48a1-bdb5-e9248fb4f1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# plot the f scores\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(fscores):\n",
        "    print(\"History:\", fscores)\n",
        "    print(\"Highest f-score:\", max(fscores))\n",
        "    plt.plot(fscores)\n",
        "    plt.legend(loc='lower center', borderaxespad=0.)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(evaluation_function.fscore)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "History: [0.24312434212301962, 0.3374537622325232, 0.36395308326559056, 0.367882814448652, 0.36785803891157076, 0.4072775473553683, 0.3733041770796145, 0.3764120406051131, 0.38586002989148094, 0.3881813997325911, 0.38661139259941657, 0.3761005443914242, 0.38683072533547325, 0.38913090360146646, 0.359850180207769, 0.40275129100687823, 0.3823096039233797, 0.36291402553343455, 0.3837400513056633, 0.3806617550895855]\n",
            "Highest f-score: 0.4072775473553683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cwMwwo9-MPv4"
      },
      "source": [
        "## 1.2 Expand context\n",
        "\n",
        "Modify your network in such way that it is able to utilize the surrounding context of the word. This can be done for instance with a convolutional or recurrent layer. Analyze different neural network architectures and hyperparameters. How does utilizing the surrounding context influence the predictions?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw9pXRewbyX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#expanding to RNN model with context\n",
        "\n",
        "from keras.layers import LSTM\n",
        "\n",
        "example_count, sequence_len = vectorized_data_padded.shape\n",
        "class_count = len(label_set)\n",
        "rnn_size = 100\n",
        "\n",
        "vector_size= pretrained.shape[1]\n",
        "\n",
        "def build_rnn_model(example_count, sequence_len, class_count, rnn_size, vocabulary, vector_size, pretrained):\n",
        "    inp=Input(shape=(sequence_len,))\n",
        "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=False, trainable=False, weights=[pretrained])(inp)\n",
        "    rnn = LSTM(rnn_size, activation='sigmoid', return_sequences=True)(embeddings)\n",
        "    outp=Dense(class_count, activation=\"softmax\")(rnn)\n",
        "    return Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "rnn_model = build_rnn_model(example_count, sequence_len, class_count, rnn_size, vocabulary, vector_size, pretrained)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPP-kwoNXUMb",
        "colab_type": "code",
        "outputId": "20faaf0a-8f64-4e4d-ccdc-7b411571d25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 561)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 561, 300)          15000600  \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 561, 100)          30100     \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 561, 37)           3737      \n",
            "=================================================================\n",
            "Total params: 15,034,437\n",
            "Trainable params: 33,837\n",
            "Non-trainable params: 15,000,600\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIal9meVXnN_",
        "colab_type": "code",
        "outputId": "86ea3cfe-d449-46c1-ea36-38b7fe2b86a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "\n",
        "optimizer=Adam(lr=0.007) # define the learning rate\n",
        "rnn_model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
        "\n",
        "evaluation_function=EvaluateEntities()\n",
        "\n",
        "# train\n",
        "rnn_hist=rnn_model.fit(vectorized_data_padded,vectorized_labels_padded, sample_weight=weights, batch_size=100,verbose=2,epochs=5, callbacks=[evaluation_function])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " - 225s - loss: 0.0133\n",
            "\n",
            "Precision/Recall/F-score: 0.5272015655577299 / 0.1460796009109641 / 0.22877038043478265\n",
            "Epoch 2/5\n",
            " - 219s - loss: 0.0073\n",
            "\n",
            "Precision/Recall/F-score: 0.5615915430920569 / 0.2765426743303329 / 0.3705946469662105\n",
            "Epoch 3/5\n",
            " - 222s - loss: 0.0063\n",
            "\n",
            "Precision/Recall/F-score: 0.5793166765033773 / 0.3193435274554459 / 0.41172632363907535\n",
            "Epoch 4/5\n",
            " - 223s - loss: 0.0058\n",
            "\n",
            "Precision/Recall/F-score: 0.5770592674290358 / 0.3593608791526588 / 0.442904878592114\n",
            "Epoch 5/5\n",
            " - 224s - loss: 0.0055\n",
            "\n",
            "Precision/Recall/F-score: 0.5915234822451317 / 0.3733506850305462 / 0.457770981539348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRKNs4t8X3Ed",
        "colab_type": "code",
        "outputId": "9e9e21c3-f5b7-4539-fd18-3d9e89a28354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plot_history(evaluation_function.fscore)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "History: [0.22877038043478265, 0.3705946469662105, 0.41172632363907535, 0.442904878592114, 0.457770981539348]\n",
            "Highest f-score: 0.457770981539348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxVhZ338c8vISFAwh62hBCWsKOIEZfWfcNSiT51nqFOp9rHDmNbqx2nnbYutbW1deqMM23H1tJWO9OOY1cgboNaxWpbkSBRdggBIYGQECAkkD2/549cMIYELnCTc5fv+/Xi5b33nJv7zZH7zeGcX841d0dEROJXUtABRESkZ6noRUTinIpeRCTOqehFROKcil5EJM71CTpAZ8OHD/fc3NygY4iIxJTVq1fvc/fMrpZFXdHn5uZSVFQUdAwRkZhiZu91t0yHbkRE4pyKXkQkzqnoRUTinIpeRCTOqehFROKcil5EJM6p6EVE4lzUzdGLiCQKd6eqrpGte+vYsreW1D5J/M354yL+Oip6EZFeUF3XyJa9dWytrGXL3lq2VNSxpbKWg0eaj61zTs5gFb2ISLQ7eKSJLaE99K17a9m8t5ate+uoPtx0bJ2MtD5MHpnBdTNHMXlkBpNHZpA3Mp3M9L49kklFLyJyGg41NLN1b+2xUt8Sul1V23hsnfS+fZg0Ip0rp404VuiTR2YwcmBfzKzXsqroRUROoK6xha2hvfItHfbQKw41HFunX0oyeSPTuSQvkymj0skLFfqYQWm9WujdCavozWwe8D0gGfipuz/czXofA34LnOfuRWaWC2wENodWedPdbz/T0CIikXakqYWSyrr24+gdCr38YP2xdfr2SWLSiHQunDgstHeezuSRGWQN7kdSUvCF3p2TFr2ZJQOPAVcDZcAqMyt09w2d1ssA7gJWdvoS29x9doTyioickYbmVkoqj54Ufb/Uyw7U496+TmpyEhMyB3DuuCF8fO7YY4dcxg7tT3IUF3p3wtmjnwuUuHspgJk9DRQAGzqt903gn4EvRTShiMhpaGxppbTqcOik6PvH0XfuP0JbqND7JBkTMgdwVvZgbpoz9thhl3FD+9MnOX5+zSicos8CdnW4Xwac33EFM5sDjHX358ysc9GPN7M1wCHgPnd/vfMLmNkiYBFATk7OKcQXkUTX3NrG9n2Hj50MPbqH/l71EVpDjZ6cZOQO68+00QNZMDuLKaHDLrnDB5ASR4XenTM+GWtmScCjwK1dLN4D5Lh7tZmdCyw1sxnufqjjSu6+GFgMkJ+f72eaSUTiT0trGzuqj7w/6VJZy5aKWrbvO0xLqNCTDMYNG0DeiHTmzxodOimazvjhA+jbJzng7yA44RR9OTC2w/3s0GNHZQAzgRWhs8ujgEIzW+DuRUAjgLuvNrNtwGRAHyElIl1qbXN27j9ybA796PhiadVhmlrbADCDsUP6M3lkOldPH3lsDn1iZjppKYlb6N0Jp+hXAXlmNp72gl8I3Hx0obvXAMOP3jezFcAXQ1M3mcB+d281swlAHlAawfwiEqPa2pyyA/Xth1wq24+jb66oZVtVHY0tbcfWyxrcj8kj07l0cuaxk6KTRqTTL1WFHq6TFr27t5jZHcBy2scrn3D39Wb2IFDk7oUnePolwINm1gy0Abe7+/5IBBeR2ODulB+s73BCtP2/JZV11De3Hltv9KA08kZmcNHEYUwe9X6hp/fVr/ucKXOPrkPi+fn5rg8HF4ld7k7xroMUvrObNTsPsnVvLYeb3i/0ERl9jx1qmTIyg7zQ7YFpKQGmjn1mttrd87taph+VIhIR26rqWLamnGXv7Oa96iOk9kliTs5gbjo3+9geet6IdAb3Tw06asJR0YvIaauoaeDZd3eztLicdeWHMIOLJg7jc5dPYt7MUdpLjxIqehE5JTX1zfzvuj0sK97NX0qrcYezsgdx3/xpLDh7DCMGpgUdUTpR0YvISTU0t/LqpkqWFpfz6qYqmlrbyB3WnzuvyGPB7DFMzEwPOqKcgIpeRLrU2ua8WVrN0jXl/O+6CmobWxie3pe/uSCHgtlZnJ09KCquzCgnp6IXkWPcnbXlNSwr3s0z7+ymsraR9L59uHbGKG44ZwwXThgWV9eASRQqehFh+77DLCsup7B4N6X7DpOanMRlUzIpmJ3FldNG6LdNY5yKXiRBVdY28Ow7e1hWXM47ZTWYwfnjh7LokglcN3M0g/prYiZeqOhFEkhtQzPL1+9lWXE5fyrZR5vD9NEDuecjU7n+7DGMHtQv6IjSA1T0InGusaWVFZurKCzezcsb99LY0sbYof347GWTKJg9hryRGUFHlB6moheJQ21tzsrt+1lWXM7za/dwqKGFYQNSWXjeWBbMzmJOzmBNzCQQFb1InHB3Nuw5xLLi3RQW76biUAP9U5O5dsYoCmaP4UOThifEh2zI8VT0IjFuZ/URCt8pZ2nxbkoq6+iTZFw6OZN75k/j6mkjdTlfUdGLxKJ9dY089277xMzbOw8CMDd3KN+6YSbzZ41myABdOEzep6IXiRGHG1t4cUMFS9fs5o2SfbS2OVNHZfDleVO5/uzRZA/pH3REiVIqepEo1tTSxutbq1havJuXNlTQ0NxG1uB+LLpkAgWzxzB11MCgI0oMUNGLRJm2NqfovQPHJmYOHGlmSP8Ubjo3m4LZWZybM4SkJE3MSPhU9CJRYlPF+xMz5QfrSUtJ4prp7RMzF+dlktpHEzNyelT0IgEqO3CEwnfay31TRS3JScbFecP50rVTuHr6SAbo81IlAvS3SKSXHTjcxHNr2ydmVu04AMC544bwYMEM5s8azbD0vgEnlHijohfpBUeaWnh5YyXL1pTz2pYqWtqcvBHpfOnaKSw4ewxjh2piRnqOil6khzS3tvFGyT4Ki3ezfH0FR5paGT0ojds+PJ6C2VlMG52hyxBIr1DRi0SQu/P2zoMsKy7nuXf3UH24iYFpfSiYPYaC2VnMzR2qiRnpdSp6kQjYureWZcW7WfZOObv219O3TxJXTR9JwdljuHRKJn376DIEEhwVvchp2lNTzzPv7Gbpmt1s2HOIJIMPTRrOXVdO5toZI8lI0wd3SHRQ0YucgpojzTy/rn1iZuX2/bjD2WMH88D105l/1mhGZKQFHVHkOCp6kTCs2XmAn7xeyksb9tLc6kwYPoAvXDmZgtljyB0+IOh4Iiekohfphrvz2pYqHn9tG2+W7mdQvxQ+eWEuN8zOYmbWQE3MSMxQ0Yt00tLaxnNr9/D4a6Vs3HOIUQPTuG/+NBbOzSFdv6kqMUh/a0VCGppb+U3RLha/Xsqu/fVMzBzAIzedRcHsLF1nRmKail4SXs2RZn7x5g6e/NMOqg83cU7OYO6bP52rp43UzLvEBRW9JKyKmgZ+9kYpT63cyeGmVi6bkslnLp3I3PFDdfxd4oqKXhJOSWUdi/+4jSVrymlz+OhZo/n7SyYyfYw+xEPik4peEsaanQd4/LVtvLhhL6nJSXx8bg5/d/EEXVBM4l5YRW9m84DvAcnAT9394W7W+xjwW+A8dy8KPfZV4DagFbjT3ZdHIrhIOI6OSP5oxTZWbm8fkfz85ZO45aJcXQ5YEsZJi97MkoHHgKuBMmCVmRW6+4ZO62UAdwErOzw2HVgIzADGAC+b2WR3b43ctyByvO5GJD8+N0cf5iEJJ5y/8XOBEncvBTCzp4ECYEOn9b4J/DPwpQ6PFQBPu3sjsN3MSkJf7y9nGlykKxqRFDleOEWfBezqcL8MOL/jCmY2Bxjr7s+Z2Zc6PffNTs/N6vwCZrYIWASQk5MTXnKRDroakbx//nSu0oikyJmfjDWzJOBR4NbT/RruvhhYDJCfn+9nmkkSx56aen72+nb+5632EcnLp2Ryu0YkRT4gnKIvB8Z2uJ8deuyoDGAmsCL0xhoFFJrZgjCeK3JaSirr+PFr21ha3D4ief1Zo/n7SycybbRGJEU6C6foVwF5Zjae9pJeCNx8dKG71wDDj943sxXAF929yMzqgafM7FHaT8bmAW9FLr4kmrd3HuDxFdt4aWP7iOTNc3P4tEYkRU7opEXv7i1mdgewnPbxyifcfb2ZPQgUuXvhCZ673sx+TfuJ2xbgc5q4kVOlEUmRM2Pu0XVIPD8/34uKioKOIVGg84jk0Q/W1oikyPHMbLW753e1TO8WiTr1Ta38ZvUufqIRSZGIUNFL1Kg50sx//WUHP/+zRiRFIklFL4HTiKRIz1LRS2BKKmv58WulGpEU6WEqeul1R0ckX9ywl7QUjUiK9DQVvfQKd2fFlioe7zAieecVGpEU6Q0qeulRXY1I6iqSIr1L7zTpEUdHJBf/sZSyA/VMGpGuEUmRgKjoJaI6j0jOyRnM1z6qEUmRIKnoJSKOjkg+9dZOjoRGJD9z2STOyx2iEUmRgKno5YxoRFIk+qno5bRoRFIkdqjoJWwakRSJTSp6OamjI5I/WrGNTRW1GpEUiTF6l0q3uhqR/Je/OpsFZ4/RiKRIDFHRy3GOjkg++ecd7NeIpEjMU9HLMRqRFIlPKnrRiKRInFPRJ7C1ZTX84JWtGpEUiXMq+gRVUlnLx370Z/qlJnPnlXnccuE4jUiKxCkVfQJyd+5dso5+qcm8fPelZGao4EXimWbkEtBvV5excvt+vnLdVJW8SAJQ0SeY/Yeb+PbzG8kfN4S/zh8bdBwR6QUq+gTznec3UtvQwkM3ztJMvEiCUNEnkDdLq/nN6jL+7pIJTBmVEXQcEeklKvoE0djSyr1L1jJ2aD/uvCIv6Dgi0os0dZMgFr9Wyraqwzz5qfPol5ocdBwR6UXao08AO/Yd5gevljB/1mgunzIi6Dgi0stU9HHO3bl/2Tr6JifxteunBx1HRAKgoo9zhe/s5vWt+/jitVMYOTAt6DgiEgAVfRyrqW/mm89u5KzsQXzignFBxxGRgOhkbBz77v9uYv/hRn7+qfNI1sy8SMLSHn2cWv3eAZ56aye3XjSemVmDgo4jIgFS0ceh5tY27l2yllED07j7mslBxxGRgIVV9GY2z8w2m1mJmX2li+W3m9laMys2szfMbHro8Vwzqw89Xmxmj0f6G5DjPfHGdjZV1PL1BTNI14d3iyS8k7aAmSUDjwFXA2XAKjMrdPcNHVZ7yt0fD62/AHgUmBdats3dZ0c2tnSn7MAR/v3lrVw1bSTXzhgVdBwRiQLh7NHPBUrcvdTdm4CngYKOK7j7oQ53BwAeuYgSLnfngWXrMYNvFMwIOo6IRIlwij4L2NXhflnosQ8ws8+Z2Tbgu8CdHRaNN7M1ZvaamV3c1QuY2SIzKzKzoqqqqlOILx0tX1/BHzZV8g9XTSZrcL+g44hIlIjYyVh3f8zdJwJfBu4LPbwHyHH3c4C7gafM7LhPnHb3xe6e7+75mZmZkYqUUOoaW/h64QamjR7Ipz6UG3QcEYki4RR9OdDxEyqyQ49152ngBgB3b3T36tDt1cA2QGMgPeBfX9zM3toGvn3jTPoka5hKRN4XTiOsAvLMbLyZpQILgcKOK5hZx+vezge2hh7PDJ3MxcwmAHlAaSSCy/vWldfwn3/ewd+cn8M5OUOCjiMiUeakUzfu3mJmdwDLgWTgCXdfb2YPAkXuXgjcYWZXAc3AAeCW0NMvAR40s2agDbjd3ff3xDeSqFrbnK/+fi3D0vvypWunBh1HRKJQWEPW7v488Hynx77W4fZd3Tzvd8DvziSgnNh//WUHa8tr+MHHz2FQv5Sg44hIFNLB3BhWUdPAv764hUsmZ/LRs0YHHUdEopSKPoZ945n1NLe28a2CmZjpomUi0jUVfYx6ZdNeXlhXwZ1X5pEzrH/QcUQkiqnoY9CRphbuX7qevBHp/N3FE4KOIyJRTle8ikHf+8NWyg/W8+u/v5DUPvpZLSInppaIMZsqDvGz17fzf/OzmTt+aNBxRCQGqOhjSFubc8/v1zKwXwpfvW5a0HFEJEao6GPI06t28fbOg9zzkWkMGZAadBwRiREq+hhRVdvIwy9s5IIJQ/nYnOMuHioi0i0VfYz41nMbaGhu46EbZ2lmXkROiYo+Bry+tYplxbu5/bKJTMxMDzqOiMQYFX2Ua2hu5f6l6xg/fACfvWxi0HFEJAZpjj7K/fDVEnZUH+GXt51PWkpy0HFEJAZpjz6KlVTW8aPXtnHD7DF8OG940HFEJEap6KOUu3PvkrX0S0nm3vnTg44jIjFMRR+lfvd2OSu37+cr100jM6Nv0HFEJIap6KPQ/sNNPPTcBs4dN4SF5409+RNERE5ARR+FvvP8RmobWnjoxpkkJWlmXkTOjIo+yqwsreY3q8v49MUTmDpqYNBxRCQOqOijSFNLG/cuXUf2kH7cdWVe0HFEJE5ojj6KLP7jNkoq63jy1vPol6qZeRGJDO3RR4n3qg/zg1dK+MisUVw+dUTQcUQkjqjoo4C7c9/SdaQkJ/HA9TOCjiMicUZFHwWeeXcPr2/dxxevmczIgWlBxxGROKOiD1hNfTMPPrOBs7IH8bcX5gYdR0TikE7GBuyR5ZvYf7iRn3/qPJI1My8iPUB79AF6e+cB/nvlTm69aDwzswYFHUdE4pSKPiDNrW3c8/u1jBqYxt3XTA46jojEMRV9QJ7803Y2VdTywPUzSO+rI2gi0nNU9AEoO3CEf3tpK1dNG8G1M0YGHUdE4pyKvpe5O18vXA/A1xfM0Ad9i0iPU9H3suXr9/Lyxkr+4eo8sof0DzqOiCQAFX0vqmts4euF65k6KoNPfWh80HFEJEHoLGAvevTFLeytbeCHn5hDSrJ+xopI7wirbcxsnpltNrMSM/tKF8tvN7O1ZlZsZm+Y2fQOy74aet5mM7s2kuFjybryGn7+5+3cPDeHOTlDgo4jIgnkpEVvZsnAY8B1wHTg4x2LPOQpd5/l7rOB7wKPhp47HVgIzADmAT8Mfb2E0trm3LNkLUMH9OWf5k0NOo6IJJhw9ujnAiXuXuruTcDTQEHHFdz9UIe7AwAP3S4Annb3RnffDpSEvl5C+cVfdvBuWQ1fu346g/qlBB1HRBJMOMfos4BdHe6XAed3XsnMPgfcDaQCV3R47pudnpvVxXMXAYsAcnJywskdMypqGviXF7dwcd5wrj9rdNBxRCQBReyMoLs/5u4TgS8D953icxe7e76752dmZkYqUlR48Nn1NLe28a0bZmpmXkQCEU7RlwNjO9zPDj3WnaeBG07zuXHl1U2VPL+2gs9fMYlxwwYEHUdEElQ4Rb8KyDOz8WaWSvvJ1cKOK5hZx0+yng9sDd0uBBaaWV8zGw/kAW+deezoV9/Uyv3L1jFpRDqLLpkYdBwRSWAnPUbv7i1mdgewHEgGnnD39Wb2IFDk7oXAHWZ2FdAMHABuCT13vZn9GtgAtACfc/fWHvpeosr3/rCVsgP1/GrRBaT20cy8iATH3P3ka/Wi/Px8LyoqCjrGGdlcUcv877/Ojedk8chfnR10HBFJAGa22t3zu1qmXc0IawvNzGek9eGrH5kWdBwRERV9pD29aher3zvAvfOnM3RAatBxRERU9JFUVdvIwy9s5IIJQ/nYnON+XUBEJBAq+gh66LkN1De38q0bZmlmXkSihoo+Qt7Yuo+lxbv5zKUTmTQiPeg4IiLHqOgjoKG5fWY+d1h/Pnv5pKDjiIh8gK5HHwE/XLGN7fsO88vbzictJeEuzikiUU579GdoW1Udj6/YRsHsMXw4b3jQcUREjqOiPwPuzr1L1pKWksR98ztfol9EJDqo6M/A798u583S/Xz5uqlkZvQNOo6ISJdU9KfpwOEmHnp+I3NyBvPx8+LrGvoiEl9U9KfpOy9s5FB9M9/+P7NIStLMvIhELxX9aXhr+35+XVTGbRePZ+qogUHHERE5IRX9KWpqaeOeJWvJGtyPu67MO/kTREQCpjn6U/ST10spqazjiVvz6Z+qzSci0U979KfgverDfP8PW7lu5iiumDoy6DgiImFR0YfJ3bl/2XpSkpN44PoZQccREQmbij5Mz767hz9uqeIfr5nMqEFpQccREQmbij4MNfXNPPjsBmZlDeKTF+YGHUdE5JTobGIYHlm+ieq6Rp645TySNTMvIjFGe/QnsWbnAf575U5uuSiXWdmDgo4jInLKVPQn0NLaxj1L1jEyI41/vGZK0HFERE6LDt2cwJN/2sHGPYd4/BNzSO+rTSUisUl79N0oP1jPoy9t4cqpI7h2xqig44iInDYVfTceWLYegG8UzNAHfYtITFPRd2H5+gpe3riXL1yVR/aQ/kHHERE5Iyr6TuoaW/h64Xqmjsrg/314fNBxRETOmM4wdvJvL22h4lAD/3HzHFKS9XNQRGKfmqyDdeU1PPmn7dw8N4dzxw0JOo6ISESo6ENa25x7lqxl6IC+/NO8qUHHERGJGBV9yC/ffI93y2q4/6PTGNQvJeg4IiIRo6IH9h5q4JHlm7k4bzgLzh4TdBwRkYhS0QMPPrOBptY2vlkwUzPzIhJ3Er7oX91cyXNr9/D5yyeRO3xA0HFERCIurKI3s3lmttnMSszsK10sv9vMNpjZu2b2BzMb12FZq5kVh/4URjL8mapvauX+peuYmDmARZdOCDqOiEiPOOkcvZklA48BVwNlwCozK3T3DR1WWwPku/sRM/sM8F3gr0PL6t19doRzR8T3X9lK2YF6nl50AX37JAcdR0SkR4SzRz8XKHH3UndvAp4GCjqu4O6vuvuR0N03gezIxoy8zRW1/OSPpdx0bjYXTBgWdBwRkR4TTtFnAbs63C8LPdad24AXOtxPM7MiM3vTzG44jYwR1xaamc9I68M9H5kWdBwRkR4V0UsgmNkngHzg0g4Pj3P3cjObALxiZmvdfVun5y0CFgHk5OREMlKXflW0i9XvHeCRm85i6IDUHn89EZEghbNHXw6M7XA/O/TYB5jZVcC9wAJ3bzz6uLuXh/5bCqwAzun8XHdf7O757p6fmZl5St/AqdpX18jDL2zi/PFDuencqD/CJCJyxsIp+lVAnpmNN7NUYCHwgekZMzsH+DHtJV/Z4fEhZtY3dHs48CGg40ncXvfQcxs50tTCQzfO0sy8iCSEkx66cfcWM7sDWA4kA0+4+3ozexAocvdC4BEgHfhNqDx3uvsCYBrwYzNro/2HysOdpnV61Z9K9rFkTTmfv2ISk0akBxVDRKRXmbsHneED8vPzvaioKOJft6G5leu+9zpt7iz/wiWkpWicUkTih5mtdvf8rpYlzPXof7RiG9v3HeYXt81VyYtIQkmISyBsq6rjRyu2seDsMVyc17Mne0VEok3cF727c9+SdfRNSeK+j2pmXkQST9wX/e/fLucvpdV8ed5URmSkBR1HRKTXxXXRHzjcxEPPb+ScnMHcPLfnfxFLRCQaxXXRP/zCJmrqm/n2jbNIStLMvIgkprgt+re27+dXRbv49IfHM230wKDjiIgEJi6LvqmljXuXrCVrcD/uuiov6DgiIoGKyzn6n7xeytbKOn52Sz79U+PyWxQRCVvc7dHvrD7C9/+wlXkzRnHltJFBxxERCVxcFb27c/+ydfRJMh5YMD3oOCIiUSGuiv65tXt4bUsV/3jNFEYP6hd0HBGRqBA3RV9T38w3ntnAzKyB3HJRbtBxRESiRtycqWxsaeWcsYO544pJJGtmXkTkmLgp+hEZaSz+ZJdX6BQRSWhxU/QiPaG5uZmysjIaGhqOW5aWlkZ2djYpKSkBJBMJn4pe5ATKysrIyMggNzf3Ax896e5UV1dTVlbG+PHjA0wocnJxczJWpCc0NDQwbNiw4z5f2MwYNmxYl3v6ItFGRS9yEt19iLw+XF5ihYpeRCTOqehFROKcil7kJNz9lB4XiTYqepETSEtLo7q6+rhSPzp1k5amj6eU6GfRtldiZlXAe2fwJYYD+yIUJ5KU69RERa7MzMw+Dz30UG5ubm4/M6OtrS0pKSmpzd3ZsWNH/b333rujqqqqJeicRMn26oJynZozyTXO3TO7WhB1RX+mzKzI3aPuV2SV69Qo16lRrlOTaLl06EZEJM6p6EVE4lw8Fv3ioAN0Q7lOjXKdGuU6NQmVK+6O0YuIyAfF4x69iIh0oKIXEYlzMVn0ZjbPzDabWYmZfaWL5X3N7Feh5SvNLDdKct1qZlVmVhz68+leyvWEmVWa2bpulpuZfT+U+10zmxMluS4zs5oO2+trvZRrrJm9amYbzGy9md3VxTq9vs3CzNXr28zM0szsLTN7J5TrG12s0+vvyTBzBfKeDL12spmtMbNnu1gW2e3l7jH1B0gGtgETgFTgHWB6p3U+Czweur0Q+FWU5LoV+I8AttklwBxgXTfLPwK8ABhwAbAySnJdBjwbwPYaDcwJ3c4AtnTx/7LXt1mYuXp9m4W2QXrodgqwErig0zpBvCfDyRXIezL02ncDT3X1/yvS2ysW9+jnAiXuXuruTcDTQEGndQqA/wzd/i1wpfX8NWXDyRUId/8jsP8EqxQA/+Xt3gQGm9noKMgVCHff4+5vh27XAhuBrE6r9fo2CzNXrwttg7rQ3ZTQn85THr3+ngwzVyDMLBuYD/y0m1Uiur1iseizgF0d7pdx/F/2Y+u4ewtQAwyLglwAHwv9U/+3Zja2hzOFK9zsQbgw9E/vF8xsRm+/eOifzOfQvjfYUaDb7AS5IIBtFjoMUQxUAi+5e7fbqxffk+HkgmDek/8O/BPQ1s3yiG6vWCz6WPYMkOvuZwEv8f5PbOna27Rfv+Ns4AfA0t58cTNLB34HfMHdD/Xma5/ISXIFss3cvdXdZwPZwFwzm9kbr3syYeTq9fekmX0UqHT31T39WkfFYtGXAx1/6maHHutyHTPrAwwCqoPO5e7V7t4YuvtT4NwezhSucLZpr3P3Q0f/6e3uzwMpZja8N17bzFJoL9P/dvffd7FKINvsZLmC3Gah1zwIvArM67QoiPfkSXMF9J78ELDAzHbQfoj3CjP7Zad1Irq9YrHoVwF5ZjbezFJpP1FR2GmdQuCW0O2bgFc8dFYjyFydjuEuoP0YazQoBD4ZmiS5AKhx9z1BhzKzUUePS5rZXNr/vvZ4OYRe82fARnd/tJvVen2bhZMriG1mZplmNjh0ux9wNbCp02q9/p4MJ1cQ76Hmc8IAAADeSURBVEl3/6q7Z7t7Lu098Yq7f6LTahHdXn1O94lBcfcWM7sDWE77pMsT7r7ezB4Eity9kPY3wy/MrIT2k30LoyTXnWa2AGgJ5bq1p3MBmNn/0D6NMdzMyoAHaD8xhbs/DjxP+xRJCXAE+FSU5LoJ+IyZtQD1wMJe+IEN7XtcfwusDR3fBbgHyOmQLYhtFk6uILbZaOA/zSyZ9h8sv3b3Z4N+T4aZK5D3ZFd6cnvpEggiInEuFg/diIjIKVDRi4jEORW9iEicU9GLiMQ5Fb2ISJxT0YuIxDkVvYhInPv/vmHh4WcqWiQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sCo0xF5kMMbH"
      },
      "source": [
        "## 2.1 Use deep contextual representations\n",
        "\n",
        "Use deep contextual representations. Fine-tune the embeddings with different hyperparameters. Try different models (e.g. cased and uncased, multilingual BERT). Report your results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFVOZKY7tgsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Maximum number of examples to read\n",
        "MAX_EXAMPLES = 1000\n",
        "\n",
        "# Maximum length of input sequence in tokens\n",
        "INPUT_LENGTH = 250\n",
        "\n",
        "# Number of epochs to train for\n",
        "EPOCHS = 3\n",
        "\n",
        "# Optimizer learning rate\n",
        "LEARNING_RATE = 0.00002\n",
        "\n",
        "# Training batch size\n",
        "BATCH_SIZE = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJbUTJMctmfc",
        "colab_type": "code",
        "outputId": "0dec9ecb-02ca-4eb6-a13b-0e207b8e27bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "!pip3 install keras-bert"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-bert\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/0f/cdc886c1018943ea62d3209bc964413d5aa9d0eb7e493abd8545be679294/keras-bert-0.81.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-bert) (1.18.4)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-bert) (2.3.1)\n",
            "Collecting keras-transformer>=0.30.0\n",
            "  Downloading https://files.pythonhosted.org/packages/22/b9/9040ec948ef895e71df6bee505a1f7e1c99ffedb409cb6eb329f04ece6e0/keras-transformer-0.33.0.tar.gz\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (2.10.0)\n",
            "Collecting keras-pos-embd>=0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.22.0\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Collecting keras-self-attention==0.41.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.81.0-cp36-none-any.whl size=37913 sha256=2fb414918da911c449ab33fa2864cd1c42c50bf5433efb4073aca49540d2e431\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/27/da/ffc2d573aa48b87440ec4f98bc7c992e3a2d899edb2d22ef9e\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.33.0-cp36-none-any.whl size=13260 sha256=50974af1da2088b9e9f181a6233646fd3896b20298f8b9a3a909780bc633e915\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/98/13/a28402939e1d48edd8704e6b02f223795af4a706815f4bf6d8\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=fd0efe4c0865537835ced63c05d555a547659579e51597859fe97b5b2f75d98c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=f9245f28f958133623ff21b36f33c5aac52298be2d8be9fa84ce35a6e3d0d1af\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=f02bcb21e43bd603136166370349321718301c516f935e0de941bc793b2a378c\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=43117cfb94f391d2447d675bcf91d8530749abba56a5f67f53ff08ea014c8ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=b4127245ff8c56d23d4d527be4827c8079b5843c097b83b46b53d003008d0e84\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17288 sha256=08ed231d5d19814a525921ea68b2c58390b5204f45850155b7049ca2065edf38\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n",
            "Successfully installed keras-bert-0.81.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.33.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibF6FQzCtpYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "os.environ['TF_KERAS'] = '1'    # Required to use tensorflow.python.keras with keras-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-QzI5XmGtIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a76f8208-6c49-4fbc-ae81-db31889072d6"
      },
      "source": [
        "#preprocess data\n",
        "if len(train_data) > MAX_EXAMPLES:\n",
        "    print('Note: truncating examples from {} to {}'.format(len(train_data), MAX_EXAMPLES))\n",
        "    train_data = train_data[:MAX_EXAMPLES]\n",
        "\n",
        "# Look at the data\n",
        "print(type(train_data))\n",
        "print(type(train_data[0]))\n",
        "print(train_data[0].keys())\n",
        "print(train_data[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: truncating examples from 30000 to 1000\n",
            "<class 'list'>\n",
            "<class 'dict'>\n",
            "dict_keys(['text', 'tags'])\n",
            "{'text': ['Sharon', 'Repudiates', 'the', 'Road', 'Map', '.'], 'tags': ['O', 'O', 'O', 'O', 'O', 'O']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fPqB32wIn2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dcf69a4c-aea9-40c2-9bfe-45452dc2dce2"
      },
      "source": [
        "texts = [example['text'] for example in train_data]\n",
        "labels = [example['tags'] for example in train_data]\n",
        "\n",
        "# Example text and label\n",
        "print('Text:', texts[0])\n",
        "print('Label:', labels[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: ['Sharon', 'Repudiates', 'the', 'Road', 'Map', '.']\n",
            "Label: ['O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXnCMZgFJUjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhHYRdgxtt4w",
        "colab_type": "code",
        "outputId": "82be40d6-396c-4bcb-9d92-5d889dadc22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "#download pretrained bert model\n",
        "# Give -nc (--no-clobber) argument so that the file isn't downloaded multiple times \n",
        "!wget -nc https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-10 16:52:04--  https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 404261442 (386M) [application/zip]\n",
            "Saving to: ‘cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "cased_L-12_H-768_A- 100%[===================>] 385.53M   160MB/s    in 2.4s    \n",
            "\n",
            "2020-05-10 16:52:06 (160 MB/s) - ‘cased_L-12_H-768_A-12.zip’ saved [404261442/404261442]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWf8U0cMuF5-",
        "colab_type": "code",
        "outputId": "f28dd7a0-00e0-49dd-b155-e094ee0705ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "# Give -n argument so that existing files aren't overwritten \n",
        "!unzip -n cased_L-12_H-768_A-12.zip\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cased_L-12_H-768_A-12.zip\n",
            "   creating: cased_L-12_H-768_A-12/\n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ynkApUUuH9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "bert_vocab_path = 'cased_L-12_H-768_A-12/vocab.txt'\n",
        "bert_config_path = 'cased_L-12_H-768_A-12/bert_config.json'\n",
        "bert_checkpoint_path = 'cased_L-12_H-768_A-12/bert_model.ckpt'    # suffixes not required"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEYyqSszuNd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_is_cased = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtC5HXQ1JiiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c54e8abc-aa36-488c-a5ae-2df119808d3a"
      },
      "source": [
        "\n",
        "vocab = []\n",
        "with open(bert_vocab_path) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        vocab.append(line.rstrip('\\n'))    # rstrip to remove newline characters\n",
        "\n",
        "\n",
        "# Print a list with every 500th vocabulary item\n",
        "print(vocab[0::500])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[PAD]', 'щ', '吉', 'told', 'space', 'operations', 'proposed', 'Oxford', 'showing', 'domestic', 'mountains', 'commission', 'voices', 'associate', 'hills', 'Guide', 'relaxed', 'Page', 'Heights', 'singers', 'Interior', 'considers', 'facilitate', 'shouting', '1826', 'constitute', 'alter', 'clip', 'Into', 'Memory', 'ballad', 'Owens', 'Langdon', 'aquatic', 'stereo', 'Cass', 'Shock', '195', '##tec', '##sonic', 'attested', '##rdes', '1840s', '##90', 'Guys', '##rien', 'Munro', 'Ursula', 'mesh', 'diplomacy', 'Newmarket', '##oughs', 'synthesizers', 'Drugs', 'monstrous', '##ynamic', 'troll', '##ٹ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jesSbptUJmvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9c10b2f7-ac22-45f5-d43f-16519d236639"
      },
      "source": [
        "from pprint import pprint    # pretty-printer for output\n",
        "import json\n",
        "\n",
        "with open(bert_config_path) as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "\n",
        "# Print configuration contents\n",
        "pprint(config)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'attention_probs_dropout_prob': 0.1,\n",
            " 'hidden_act': 'gelu',\n",
            " 'hidden_dropout_prob': 0.1,\n",
            " 'hidden_size': 768,\n",
            " 'initializer_range': 0.02,\n",
            " 'intermediate_size': 3072,\n",
            " 'max_position_embeddings': 512,\n",
            " 'num_attention_heads': 12,\n",
            " 'num_hidden_layers': 12,\n",
            " 'type_vocab_size': 2,\n",
            " 'vocab_size': 28996}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ck95HuSJkxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "10944ba2-00d2-46aa-f2bd-bf8d3bfb7008"
      },
      "source": [
        "\n",
        "# Create mapping from vocabulary items to their indices in the vocabulary\n",
        "token_dict = { v: i for i, v in enumerate(vocab) }\n",
        "\n",
        "\n",
        "# Print some random examples of the mapping\n",
        "pprint(dict(random.choices(list(token_dict.items()), k=10)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'##bor': 12207,\n",
            " '##utile': 26555,\n",
            " 'However': 1438,\n",
            " 'Title': 11772,\n",
            " 'calcium': 15355,\n",
            " 'celebrities': 13073,\n",
            " 'compares': 26153,\n",
            " 'dome': 10945,\n",
            " 'tap': 12999,\n",
            " 'threatens': 18241}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJpCRLnvuRvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7fd50548-4dc4-4293-bd3e-7dcfac5fd9a9"
      },
      "source": [
        "\n",
        "from keras_bert import Tokenizer\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(token_dict, cased=model_is_cased)\n",
        "\n",
        "\n",
        "#Let's test that out\n",
        "for s in ['Hello BERT!', 'Unknown: 你']:\n",
        "    print('Original string:', s)\n",
        "    print('Tokenized:', tokenizer.tokenize(s))\n",
        "    indices, segments = tokenizer.encode(s, max_len=20)    # max_len for padding and truncation\n",
        "    print('Encoded:', indices)\n",
        "    print('Segments:', segments)\n",
        "    print('Decoded:', ' '.join(tokenizer.decode(indices)))\n",
        "    print()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original string: Hello BERT!\n",
            "Tokenized: ['[CLS]', 'Hello', 'B', '##ER', '##T', '!', '[SEP]']\n",
            "Encoded: [101, 8667, 139, 9637, 1942, 106, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Segments: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoded: Hello B ##ER ##T !\n",
            "\n",
            "Original string: Unknown: 你\n",
            "Tokenized: ['[CLS]', 'Unknown', ':', '你', '[SEP]']\n",
            "Encoded: [101, 16285, 131, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Segments: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Decoded: Unknown : [UNK]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVwL4OcGajvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_flattened = []    #make list of lists into one list\n",
        "for i in labels:\n",
        "  for j in i:\n",
        "    labels_flattened. append(j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42qIdXtspgDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_flattened = []\n",
        "texts[0][0]+' '+texts[0][1]\n",
        "for i in texts:\n",
        "  try:\n",
        "    texts_flattened.append(auxi)\n",
        "  except:\n",
        "      pass\n",
        "  #helper = []\n",
        "  auxi = ''\n",
        "  for j in i:\n",
        "    auxi = auxi + str(j) + ' '\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCwfMm_yru2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7783827-7eaf-49c5-be1d-373653c223d8"
      },
      "source": [
        "texts_flattened[0]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sharon Repudiates the Road Map . '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4fH-6HxpRDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a94b2c85-2be5-45c1-d925-c1a96cf4b734"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "token_indices, segment_ids = [], []\n",
        "for text in texts_flattened:\n",
        "    # tokenizer.encode() returns a sequence of token indices\n",
        "    # and a sequence of segment IDs. BERT expects both as input,\n",
        "    # even if the segments IDs are just all zeros (like here).\n",
        "    tid, sid = tokenizer.encode(text, max_len=INPUT_LENGTH)\n",
        "    token_indices.append(tid)\n",
        "    segment_ids.append(sid)\n",
        "\n",
        "# Format input as list of two numpy arrays\n",
        "X = [np.array(token_indices), np.array(segment_ids)]\n",
        "\n",
        "\n",
        "# Print some examples\n",
        "print('Token indices:')\n",
        "print(X[0][:2])\n",
        "print('Decoded:')\n",
        "for i in X[0][:2]:\n",
        "    print(tokenizer.decode(list(i)))\n",
        "print('Segment ids:')\n",
        "print(X[1][:2])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices:\n",
            "[[  101 10562 20777 17294  5430  1103  1914 21824   119   102     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [  101  7302 27780  1110  1198  1141  1104  1317  7230  3483  1111  1292\n",
            "   1826   113  1122  1108   183   112   189  1256  1103  1148   117   171\n",
            "   1204  2246   132 11696  1197  1942 23074  3073 20388  1122   114   119\n",
            "    102     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]]\n",
            "Decoded:\n",
            "['Sharon', 'Rep', '##udi', '##ates', 'the', 'Road', 'Map', '.']\n",
            "['Apple', '##Script', 'is', 'just', 'one', 'of', 'several', 'client', 'languages', 'for', 'these', 'services', '(', 'it', 'was', 'n', \"'\", 't', 'even', 'the', 'first', ',', 'b', '##t', '##w', ';', 'Use', '##r', '##T', '##alk', 'pre', '##dates', 'it', ')', '.']\n",
            "Segment ids:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1PJ__dUvOD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load pretrained bert model\n",
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "\n",
        "pretrained_model = load_trained_model_from_checkpoint(\n",
        "    config_file = bert_config_path,\n",
        "    checkpoint_file = bert_checkpoint_path,\n",
        "    training = False,\n",
        "    trainable = True,\n",
        "    seq_len = INPUT_LENGTH\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0UNV9ECvknx",
        "colab_type": "code",
        "outputId": "69c15b72-7cc5-4017-b620-054f4a828ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# model.outputs is a list, here with a single item. We'll\n",
        "# add our output layer on top of that.\n",
        "bert_out = pretrained_model.outputs[0]\n",
        "\n",
        "print(bert_out)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Encoder-12-FeedForward-Norm_1/Identity:0\", shape=(None, 250, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-GdDIltv8X6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = len(label_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lSYfw24vnwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import TimeDistributed, Dense\n",
        "\n",
        "\n",
        "out = TimeDistributed(Dense(num_labels, activation='softmax'))(bert_out)\n",
        "model = Model(\n",
        "    inputs=pretrained_model.inputs,\n",
        "    outputs=[out]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2shPM4ywNCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create optimizer\n",
        "\n",
        "from keras_bert import calc_train_steps, AdamWarmup\n",
        "\n",
        "\n",
        "# Calculate the number of steps for warmup\n",
        "total_steps, warmup_steps = calc_train_steps(\n",
        "    num_example=len(sentences_train),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    warmup_proportion=0.1,\n",
        ")\n",
        "\n",
        "optimizer = AdamWarmup(\n",
        "    total_steps,\n",
        "    warmup_steps,\n",
        "    lr=LEARNING_RATE,\n",
        "    epsilon=1e-6,\n",
        "    weight_decay=0.01,\n",
        "    weight_decay_pattern=['embeddings', 'kernel', 'W1', 'W2', 'Wk', 'Wq', 'Wv', 'Wo']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzM6dkHIwq_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluation metric\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "def label_categorical_accuracy(y_true, y_pred):\n",
        "    # Map one-hot targets and predictions to tag indices \n",
        "    y_true_idx = o.argmax(y_true, axis=-1)\n",
        "    y_pred_idx = o.argmax(y_pred, axis=-1)\n",
        "    # Compare targets to predicted elementwise and cast the\n",
        "    # resulting boolean values to floating point values.\n",
        "    # (K.floatx() returns current default float type.)\n",
        "    correct_preds = o.cast(o.equal(y_true_idx, y_pred_idx), K.floatx())\n",
        "    # Compare targets to the special NO_LABEL value and cast\n",
        "    # the resulting boolean values to floating point values.\n",
        "    # This gives a value of zero for NO_LABEL and one for others.\n",
        "    is_label = o.cast(o.not_equal(y_true_idx, tag_to_int[NO_LABEL]), K.floatx())\n",
        "    # Take elementwise product of the comparisons, giving values that\n",
        "    # are one if the prediction is equal to the target and the target\n",
        "    # is not the NO_LABEL value, and zero otherwise.\n",
        "    correct_label_preds = o.multiply(correct_preds, is_label)\n",
        "    # Accuracy is then the number of correct predictions for labels\n",
        "    # divided by the number of labels.\n",
        "    return o.reduce_sum(correct_label_preds)/o.reduce_sum(is_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt0YfB-6wxY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train model\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLfJdABnw1EL",
        "colab_type": "code",
        "outputId": "bccc20c5-3d4e-4890-b7c8-69aebfafc358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "history = model.fit(\n",
        "    X,\n",
        "    Y,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-07f1fab4f8d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [8 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [8 250]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at <ipython-input-86-07f1fab4f8d1>:6) ]]\n\t [[gradient_tape/model_4/Embedding-Token/embedding_lookup/Reshape/_204]]\n  (1) Invalid argument:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [8 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [8 250]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at <ipython-input-86-07f1fab4f8d1>:6) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_127132]\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgSYNcerMI9R"
      },
      "source": [
        "## 2.2 Error analysis\n",
        "\n",
        "Select one model from each of the previous milestones (three models in total). Look at the entities these models predict. Analyze the errors made. Are there any patterns? How do the errors one model makes differ from those made by another?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pODn-BJ_uNAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sRHpWGquHNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aRDxKgLSL_uf"
      },
      "source": [
        "## 3.1 Predictions on unannotated text\n",
        "\n",
        "Use the three models selected in milestone 2.2 to do predictions on the sampled wikipedia text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wlG6ZWkIL-HY"
      },
      "source": [
        "## 3.2 Statistically analyze the results\n",
        "\n",
        "Statistically analyze (i.e. count the number of instances) and compare the predictions. You can, for example, analyze if some models tend to predict more entities starting with a capital letter, or if some models predict more entities for some specific classes than others."
      ]
    }
  ]
}