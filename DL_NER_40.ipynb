{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainvo/DeepLearning_NER/blob/master/DL_NER_40.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hTBsYI1tLeVk"
      },
      "source": [
        "# Deep Learning NER task\n",
        "\n",
        "Tatjana Cucic and Sanna Volanen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T2GevEzfPP2",
        "colab_type": "text"
      },
      "source": [
        "https://spacy.io/api/annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O5MwAmUALZ4V"
      },
      "source": [
        "# Milestones\n",
        "\n",
        "## 1.1 Predicting word labels independently\n",
        "\n",
        "* The first part is to train a classifier which assigns a label for each given input word independently. \n",
        "* Evaluate the results on token level and entity level. \n",
        "* Report your results with different network hyperparameters. \n",
        "* Also discuss whether the token level accuracy is a reasonable metric.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Q3HiGQgMU5L",
        "outputId": "6beca9c0-e368-4688-9c82-ffc0fdd80f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# Training data: Used for training the model\n",
        "!wget https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/train.tsv\n",
        "\n",
        "# Development/ validation data: Used for testing different model parameters, for example level of regularization needed\n",
        "!wget https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/dev.tsv\n",
        "\n",
        "# Test data: Never touched during training / model development, used for evaluating the final model\n",
        "!wget https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/test.tsv\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-11 13:54:48--  https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17252156 (16M) [text/plain]\n",
            "Saving to: ‘train.tsv’\n",
            "\n",
            "train.tsv           100%[===================>]  16.45M  49.8MB/s    in 0.3s    \n",
            "\n",
            "2020-05-11 13:54:49 (49.8 MB/s) - ‘train.tsv’ saved [17252156/17252156]\n",
            "\n",
            "--2020-05-11 13:54:51--  https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/dev.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2419425 (2.3M) [text/plain]\n",
            "Saving to: ‘dev.tsv’\n",
            "\n",
            "dev.tsv             100%[===================>]   2.31M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-11 13:54:52 (20.8 MB/s) - ‘dev.tsv’ saved [2419425/2419425]\n",
            "\n",
            "--2020-05-11 13:54:54--  https://raw.githubusercontent.com/sainvo/DeepLearning_NER/master/test.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1788466 (1.7M) [text/plain]\n",
            "Saving to: ‘test.tsv’\n",
            "\n",
            "test.tsv            100%[===================>]   1.71M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-05-11 13:54:55 (38.1 MB/s) - ‘test.tsv’ saved [1788466/1788466]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZhc7b6VFWYX",
        "colab_type": "code",
        "outputId": "6eaf32a7-ab31-4b41-bcc9-80359f5347ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys \n",
        "import csv\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zOOHEYpiMzFp",
        "outputId": "a065e002-cdaa-4ab7-b5c3-86b0d5b3f521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#read tsv data to list of lists of lists: a list of sentences that contain lists of tokens that are lists of unsplit \\t lines from the tsv, such as ['attract\\tO']\n",
        "token = {\"word\":\"\",\"entity_label\":\"\"}\n",
        "\n",
        "def read_ontonotes(tsv_file): # \n",
        "    current_sent = [] # list of (word,label) lists\n",
        "    with open(tsv_file) as f:\n",
        "        tsvreader = csv.reader(f, delimiter= '\\n')\n",
        "        for line in tsvreader:\n",
        "            #print(line)\n",
        "            if not line:\n",
        "                if current_sent:\n",
        "                    yield current_sent\n",
        "                    current_sent=[]\n",
        "                continue\n",
        "            current_sent.append(line) \n",
        "        else:\n",
        "            if current_sent:\n",
        "                yield current_sent\n",
        "\n",
        "full_train_data = list(read_ontonotes('train.tsv'))\n",
        "size_tr = int(len(full_train_data)/2)\n",
        "print(size_tr)\n",
        "##slice train\n",
        "train_data_sample = full_train_data[:size_tr]\n",
        "print(train_data_sample[:5])\n",
        "print()\n",
        "full_dev_data = list(read_ontonotes('dev.tsv'))\n",
        "size_dv = int(len(full_dev_data)/2)\n",
        "print(size_dv)\n",
        "#slice dev\n",
        "dev_data_sample = full_dev_data[:size_dv]\n",
        "print(dev_data_sample[:5])\n",
        "print()\n",
        "full_test_data = list(read_ontonotes('test.tsv'))\n",
        "size_ts = int(len(full_test_data)/2)\n",
        "print(size_ts)\n",
        "test_data_sample = full_test_data[:size_ts]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33409\n",
            "[[['Big\\tO'], ['Managers\\tO'], ['on\\tO'], ['Campus\\tO']], [['In\\tO'], ['recent\\tB-DATE'], ['years\\tI-DATE'], [',\\tO'], ['advanced\\tO'], ['education\\tO'], ['for\\tO'], ['professionals\\tO'], ['has\\tO'], ['become\\tO'], ['a\\tO'], ['hot\\tO'], ['topic\\tO'], ['in\\tO'], ['the\\tO'], ['business\\tO'], ['community\\tO'], ['.\\tO']], [['With\\tO'], ['this\\tO'], ['trend\\tO'], [',\\tO'], ['suddenly\\tO'], ['the\\tO'], ['mature\\tO'], ['faces\\tO'], ['of\\tO'], ['managers\\tO'], ['boasting\\tO'], ['an\\tO'], ['average\\tO'], ['of\\tO'], ['over\\tO'], ['ten\\tB-DATE'], ['years\\tI-DATE'], ['of\\tO'], ['professional\\tO'], ['experience\\tO'], ['have\\tO'], ['flooded\\tO'], ['in\\tO'], ['among\\tO'], ['the\\tO'], ['young\\tO'], ['people\\tO'], ['populating\\tO'], ['university\\tO'], ['campuses\\tO'], ['.\\tO']], [['In\\tO'], ['order\\tO'], ['to\\tO'], ['attract\\tO'], ['this\\tO'], ['group\\tO'], ['of\\tO'], ['seasoned\\tO'], ['adults\\tO'], ['pulling\\tO'], ['in\\tO'], ['over\\tO'], ['NT$\\tB-MONEY'], ['1\\tI-MONEY'], ['million\\tI-MONEY'], ['a\\tO'], ['year\\tO'], ['back\\tO'], ['to\\tO'], ['the\\tO'], ['ivory\\tO'], ['tower\\tO'], [',\\tO'], ['universities\\tO'], ['have\\tO'], ['begun\\tO'], ['to\\tO'], ['establish\\tO'], ['executive\\tO'], ['MBA\\tB-WORK_OF_ART'], ['(\\tO'], ['EMBA\\tB-WORK_OF_ART'], [')\\tO'], ['programs\\tO'], ['.\\tO']], [['In\\tO'], ['response\\tO'], [',\\tO'], ['each\\tO'], ['year\\tO'], ['over\\tO'], ['1000\\tB-CARDINAL'], ['mature\\tO'], ['professionals\\tO'], ['looking\\tO'], ['to\\tO'], ['recharge\\tO'], ['their\\tO'], ['minds\\tO'], ['and\\tO'], ['retool\\tO'], ['their\\tO'], ['know\\tO'], ['-\\tO'], ['how\\tO'], ['compete\\tO'], ['for\\tO'], ['a\\tO'], ['precious\\tO'], ['few\\tO'], ['openings\\tO'], ['in\\tO'], ['executive\\tO'], ['degree\\tO'], ['programs\\tO'], ['at\\tO'], ['top\\tO'], ['institutions\\tO'], ['such\\tO'], ['as\\tO'], ['National\\tB-ORG'], ['Taiwan\\tI-ORG'], ['University\\tI-ORG'], ['(\\tO'], ['NTU\\tB-ORG'], [')\\tO'], ['and\\tO'], ['National\\tB-ORG'], ['Chengchi\\tI-ORG'], ['University\\tI-ORG'], ['.\\tO']]]\n",
            "\n",
            "5806\n",
            "[[['President\\tB-WORK_OF_ART'], ['Chen\\tI-WORK_OF_ART'], ['Travels\\tI-WORK_OF_ART'], ['Abroad\\tI-WORK_OF_ART']], [['(\\tO'], ['Chang\\tB-PERSON'], ['Chiung\\tI-PERSON'], ['-\\tI-PERSON'], ['fang\\tI-PERSON'], ['/\\tO'], ['tr.\\tO'], ['by\\tO'], ['David\\tB-PERSON'], ['Mayer\\tI-PERSON'], [')\\tO']], [['President\\tO'], ['Chen\\tB-PERSON'], ['Shui\\tI-PERSON'], ['-\\tI-PERSON'], ['bian\\tI-PERSON'], ['visited\\tO'], ['the\\tB-FAC'], ['Nicaraguan\\tI-FAC'], ['National\\tI-FAC'], ['Assembly\\tI-FAC'], ['on\\tO'], ['August\\tB-DATE'], ['17\\tI-DATE'], [',\\tO'], ['where\\tO'], ['he\\tO'], ['received\\tO'], ['a\\tO'], ['medal\\tO'], ['from\\tO'], ['the\\tO'], ['president\\tO'], ['of\\tO'], ['the\\tO'], ['assembly\\tO'], [',\\tO'], ['Ivan\\tB-PERSON'], ['Escobar\\tI-PERSON'], ['Fornos\\tI-PERSON'], ['.\\tO']], [['(\\tO'], ['photo\\tO'], ['by\\tO'], ['Wu\\tB-PERSON'], ['Chi\\tI-PERSON'], ['-\\tI-PERSON'], ['chang\\tI-PERSON'], [',\\tO'], ['Central\\tB-ORG'], ['News\\tI-ORG'], ['Agency\\tI-ORG'], [')\\tO']], [['On\\tO'], ['August\\tB-DATE'], ['25\\tI-DATE'], ['President\\tO'], ['Chen\\tB-PERSON'], ['Shui\\tI-PERSON'], ['-\\tI-PERSON'], ['bian\\tI-PERSON'], ['wrapped\\tO'], ['up\\tO'], ['his\\tO'], ['first\\tB-ORDINAL'], ['overseas\\tO'], ['trip\\tO'], ['since\\tO'], ['taking\\tO'], ['office\\tO'], [',\\tO'], ['swinging\\tO'], ['through\\tO'], ['three\\tB-CARDINAL'], ['countries\\tO'], ['in\\tO'], ['Latin\\tB-LOC'], ['America\\tI-LOC'], ['and\\tO'], ['another\\tO'], ['three\\tB-CARDINAL'], ['in\\tO'], ['Africa\\tB-LOC'], ['.\\tO']]]\n",
            "\n",
            "4875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q32R9o_mJZAt",
        "colab_type": "code",
        "outputId": "98b0eb8d-37f3-4d02-84e2-28a269b5cf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "import re\n",
        "#regex for empty space chars, \\t \\n\n",
        "tab = re.compile('[\\t]')\n",
        "\n",
        "def clean(list):\n",
        "    clean_data =[]\n",
        "    for sent in list:\n",
        "        clean_list = []\n",
        "        for item in sent:\n",
        "            str = ''.join(item)\n",
        "            #match_nl = re.match(r\"\\n\", str)\n",
        "            #print(match_nl)\n",
        "            count_tab =  re.findall(r\"\\t\", str)\n",
        "            #print(count_tab)\n",
        "            if len(count_tab) == 1: \n",
        "                item = re.split(\"\\t\", str)\n",
        "                if item[0] != '.':\n",
        "                    clean_list.append(item)\n",
        "            elif len(count_tab) > 1:\n",
        "                item = re.split(\"\\n\", str)\n",
        "                #print(item)\n",
        "                for i in range(len(item)):\n",
        "                    #print(item[i])\n",
        "                    if i == 0 or i == len(item)-1:\n",
        "                        item[i] = '\"'+item[i]\n",
        "                        item[i] = re.split(\"\\t\", item[i])\n",
        "                        #print(item[i])\n",
        "                    else:\n",
        "                        item[i] = re.split(\"\\t\", item[i])\n",
        "                        #print(item[i])\n",
        "                    clean_list.append(item[i])\n",
        "        clean_data.append(clean_list)        \n",
        "    return clean_data\n",
        "\n",
        "train_data_clean = clean(train_data_sample)\n",
        "print(len(train_data_clean))\n",
        "for item in train_data_clean[:3]:\n",
        "    print(item)\n",
        "print('------------------------------------------')\n",
        "dev_data_clean = clean(dev_data_sample)\n",
        "print(len(dev_data_clean))\n",
        "for item in dev_data_clean[:3]:\n",
        "    print(item)\n",
        "print('------------------------------------------')\n",
        "test_data_clean = clean(test_data_sample)\n",
        "print(len(test_data_clean))\n",
        "for item in test_data_clean[:3]:\n",
        "    print(item)\n",
        "print('------------------------------------------')          "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33409\n",
            "[['Big', 'O'], ['Managers', 'O'], ['on', 'O'], ['Campus', 'O']]\n",
            "[['In', 'O'], ['recent', 'B-DATE'], ['years', 'I-DATE'], [',', 'O'], ['advanced', 'O'], ['education', 'O'], ['for', 'O'], ['professionals', 'O'], ['has', 'O'], ['become', 'O'], ['a', 'O'], ['hot', 'O'], ['topic', 'O'], ['in', 'O'], ['the', 'O'], ['business', 'O'], ['community', 'O']]\n",
            "[['With', 'O'], ['this', 'O'], ['trend', 'O'], [',', 'O'], ['suddenly', 'O'], ['the', 'O'], ['mature', 'O'], ['faces', 'O'], ['of', 'O'], ['managers', 'O'], ['boasting', 'O'], ['an', 'O'], ['average', 'O'], ['of', 'O'], ['over', 'O'], ['ten', 'B-DATE'], ['years', 'I-DATE'], ['of', 'O'], ['professional', 'O'], ['experience', 'O'], ['have', 'O'], ['flooded', 'O'], ['in', 'O'], ['among', 'O'], ['the', 'O'], ['young', 'O'], ['people', 'O'], ['populating', 'O'], ['university', 'O'], ['campuses', 'O']]\n",
            "------------------------------------------\n",
            "5806\n",
            "[['President', 'B-WORK_OF_ART'], ['Chen', 'I-WORK_OF_ART'], ['Travels', 'I-WORK_OF_ART'], ['Abroad', 'I-WORK_OF_ART']]\n",
            "[['(', 'O'], ['Chang', 'B-PERSON'], ['Chiung', 'I-PERSON'], ['-', 'I-PERSON'], ['fang', 'I-PERSON'], ['/', 'O'], ['tr.', 'O'], ['by', 'O'], ['David', 'B-PERSON'], ['Mayer', 'I-PERSON'], [')', 'O']]\n",
            "[['President', 'O'], ['Chen', 'B-PERSON'], ['Shui', 'I-PERSON'], ['-', 'I-PERSON'], ['bian', 'I-PERSON'], ['visited', 'O'], ['the', 'B-FAC'], ['Nicaraguan', 'I-FAC'], ['National', 'I-FAC'], ['Assembly', 'I-FAC'], ['on', 'O'], ['August', 'B-DATE'], ['17', 'I-DATE'], [',', 'O'], ['where', 'O'], ['he', 'O'], ['received', 'O'], ['a', 'O'], ['medal', 'O'], ['from', 'O'], ['the', 'O'], ['president', 'O'], ['of', 'O'], ['the', 'O'], ['assembly', 'O'], [',', 'O'], ['Ivan', 'B-PERSON'], ['Escobar', 'I-PERSON'], ['Fornos', 'I-PERSON']]\n",
            "------------------------------------------\n",
            "4875\n",
            "[['Powerful', 'B-WORK_OF_ART'], ['Tools', 'I-WORK_OF_ART'], ['for', 'I-WORK_OF_ART'], ['Biotechnology', 'I-WORK_OF_ART'], ['-', 'I-WORK_OF_ART'], ['Biochips', 'I-WORK_OF_ART']]\n",
            "[['(', 'O'], ['Chang', 'B-PERSON'], ['Chiung', 'I-PERSON'], ['-', 'I-PERSON'], ['fang', 'I-PERSON'], ['/', 'O'], ['photos', 'O'], ['by', 'O'], ['Hsueh', 'B-PERSON'], ['Chi', 'I-PERSON'], ['-', 'I-PERSON'], ['kuang', 'I-PERSON'], ['/', 'O'], ['tr.', 'O'], ['by', 'O'], ['Robert', 'B-PERSON'], ['Taylor', 'I-PERSON'], [')', 'O']]\n",
            "[['The', 'O'], ['enterovirus', 'O'], ['detection', 'O'], ['biochip', 'O'], ['developed', 'O'], ['by', 'O'], ['DR.', 'B-ORG'], ['Chip', 'I-ORG'], ['Biotechnology', 'I-ORG'], ['takes', 'O'], ['only', 'B-TIME'], ['six', 'I-TIME'], ['hours', 'I-TIME'], ['to', 'O'], ['give', 'O'], ['hospitals', 'O'], ['the', 'O'], ['answer', 'O'], ['to', 'O'], ['whether', 'O'], ['a', 'O'], ['sample', 'O'], ['contains', 'O'], ['enterovirus', 'O'], [',', 'O'], ['and', 'O'], ['if', 'O'], ['it', 'O'], ['is', 'O'], ['the', 'O'], ['deadly', 'O'], ['strain', 'O'], ['Entero', 'O'], ['71', 'O']]\n",
            "------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cZHhXzVTQA_P",
        "outputId": "68d3fc48-013d-482f-d5ab-492e02d224cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# shape into dicts per sentence\n",
        "\n",
        "def reshape_sent2dicts(f):\n",
        "    data_dict = []\n",
        "    for item in f: # list of lists (tokens)\n",
        "        #print(item)\n",
        "        sent_text= [] \n",
        "        sent_tags = []\n",
        "        for token in item:\n",
        "            if len(token) ==2:\n",
        "                sent_text.append(token[0])\n",
        "                sent_tags.append(token[1])\n",
        "        sent_dict = {'text':sent_text,'tags':sent_tags }\n",
        "        #print(sent_dict['text'])\n",
        "        #print(sent_dict['tags'])\n",
        "        data_dict.append(sent_dict)\n",
        "    return data_dict\n",
        "\n",
        "train_data_sent = list(reshape_sent2dicts(train_data_clean[:30000]))\n",
        "samp = train_data_sent[:3]\n",
        "print(samp)\n",
        "print()\n",
        "dev_data_sent = list(reshape_sent2dicts(dev_data_clean))\n",
        "samp2 = dev_data_sent[:3]\n",
        "print(samp2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'text': ['Big', 'Managers', 'on', 'Campus'], 'tags': ['O', 'O', 'O', 'O']}, {'text': ['In', 'recent', 'years', ',', 'advanced', 'education', 'for', 'professionals', 'has', 'become', 'a', 'hot', 'topic', 'in', 'the', 'business', 'community'], 'tags': ['O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}, {'text': ['With', 'this', 'trend', ',', 'suddenly', 'the', 'mature', 'faces', 'of', 'managers', 'boasting', 'an', 'average', 'of', 'over', 'ten', 'years', 'of', 'professional', 'experience', 'have', 'flooded', 'in', 'among', 'the', 'young', 'people', 'populating', 'university', 'campuses'], 'tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}]\n",
            "\n",
            "[{'text': ['President', 'Chen', 'Travels', 'Abroad'], 'tags': ['B-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART']}, {'text': ['(', 'Chang', 'Chiung', '-', 'fang', '/', 'tr.', 'by', 'David', 'Mayer', ')'], 'tags': ['O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O']}, {'text': ['President', 'Chen', 'Shui', '-', 'bian', 'visited', 'the', 'Nicaraguan', 'National', 'Assembly', 'on', 'August', '17', ',', 'where', 'he', 'received', 'a', 'medal', 'from', 'the', 'president', 'of', 'the', 'assembly', ',', 'Ivan', 'Escobar', 'Fornos'], 'tags': ['O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'I-FAC', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON']}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VpYBQMbcQGBi",
        "outputId": "b8109553-f16f-460a-bb96-3228293007b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import random\n",
        "import numpy\n",
        "\n",
        "random.seed(123)\n",
        "random.shuffle(train_data_sent)\n",
        "print(type(train_data_sent))\n",
        "print(type(train_data_sent[0]))\n",
        "\n",
        "train_texts=[i[\"text\"] for i in train_data_sent]\n",
        "train_labels=[i[\"tags\"] for i in train_data_sent]\n",
        "\n",
        "#print(type(train_texts))\n",
        "#print(type(train_texts[0]))\n",
        "\n",
        "print('Text: ', train_texts[:4])\n",
        "print('Labels: ', train_labels[:4])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'dict'>\n",
            "Text:  [['Sharon', 'Repudiates', 'the', 'Road', 'Map'], ['AppleScript', 'is', 'just', 'one', 'of', 'several', 'client', 'languages', 'for', 'these', 'services', '(', 'it', 'was', \"n't\", 'even', 'the', 'first', ',', 'btw', ';', 'UserTalk', 'predates', 'it', ')'], ['Your', 'qualifications', 'quote', 'end', 'quote', 'meaningless', '/.'], ['[dasanicool]', 'Young', 'people', 'like', 'to', 'race', 'high', '-', 'power', 'motorcycles', 'late', 'at', 'night', 'and', 'revel', 'in', 'bars', 'well', 'after', 'dark']]\n",
            "Labels:  [['O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNQQRw0YO-Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## same for validation/dev data\n",
        "dev_texts=[i[\"text\"] for i in dev_data_sent]\n",
        "dev_labels=[i[\"tags\"] for i in dev_data_sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNKOr6YY28eC",
        "colab_type": "text"
      },
      "source": [
        "Let's add POS tags to the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlIltk1uXIXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DO NOT RUN\n",
        "#import nltk\n",
        "#nltk.download('averaged_perceptron_tagger') \n",
        "\n",
        "#def sent_parser4pos(texts, labels):\n",
        "  #  for i in range(len(texts) -1):\n",
        "#        #print(texts[i])\n",
        "#        tokens_with_pos = nltk.pos_tag(texts[i])\n",
        "#        #getting the corresponding labels list\n",
        " #       labels_curr= labels[i]\n",
        "  #      print()\n",
        " #       print()\n",
        "        #print('current labels:',labels_curr)\n",
        "       #updating labels with pos label\n",
        "        #print('possed tokens:', tokens_with_pos)\n",
        "  #      for j in range(len(labels_curr) -1):\n",
        "   #         bio = labels_curr[j]\n",
        "  #          pos = tokens_with_pos[j][1]\n",
        "            #print('bio: ',bio)\n",
        "            #print('pos: ', pos)\n",
        "            #print('current labels: ',labels[i])\n",
        "   #         new_label = pos+' '+bio ## new kind of combination label\n",
        "   #         labels[i][j] = new_label\n",
        "        #print('No of Bio Labels: ',len(labels_curr), ' No of pos tags: ', len(tokens_with_pos), ' No of updated labels: ', len(labels[i]), labels[i])\n",
        "  #  return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCqK8iji9Nur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DO NOT RUN\n",
        "#train_labels_posbio = sent_parser4pos(train_texts, train_labels)\n",
        "#print(train_texts[0])\n",
        "#print(train_labels[0]\n",
        "#print(train_labels_posbio[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICn08fOgbyXl",
        "colab_type": "code",
        "outputId": "d63bda1d-ff41-4d95-dfd4-6ddbabc1b27f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load pretrained embeddings\n",
        "!wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘wiki-news-300d-1M.vec.zip’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFv2qclTbyXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Give -n argument so that a possible existing file isn't overwritten \n",
        "!unzip -n wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx_C5ii8byXt",
        "colab_type": "code",
        "outputId": "78585302-9936-4033-aafc-37274b79d542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "vector_model = KeyedVectors.load_word2vec_format(\"wiki-news-300d-1M.vec\", binary=False, limit=50000)\n",
        "\n",
        "\n",
        "# sort based on the index to make sure they are in the correct order\n",
        "words = [k for k, v in sorted(vector_model.vocab.items(), key=lambda x: x[1].index)]\n",
        "print(\"Words from embedding model:\", len(words))\n",
        "print(\"First 50 words:\", words[:50])\n",
        "\n",
        "# Normalize the vectors to unit length\n",
        "print(\"Before normalization:\", vector_model.get_vector(\"in\")[:10])\n",
        "vector_model.init_sims(replace=True)\n",
        "print(\"After normalization:\", vector_model.get_vector(\"in\")[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Words from embedding model: 50000\n",
            "First 50 words: [',', 'the', '.', 'and', 'of', 'to', 'in', 'a', '\"', ':', ')', 'that', '(', 'is', 'for', 'on', '*', 'with', 'as', 'it', 'The', 'or', 'was', \"'\", \"'s\", 'by', 'from', 'at', 'I', 'this', 'you', '/', 'are', '=', 'not', '-', 'have', '?', 'be', 'which', ';', 'all', 'his', 'has', 'one', 'their', 'about', 'but', 'an', '|']\n",
            "Before normalization: [-0.0234 -0.0268 -0.0838  0.0386 -0.0321  0.0628  0.0281 -0.0252  0.0269\n",
            " -0.0063]\n",
            "After normalization: [-0.0163762  -0.01875564 -0.05864638  0.02701372 -0.02246478  0.04394979\n",
            "  0.01966543 -0.0176359   0.01882563 -0.00440898]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkdgjgOlbyXx",
        "colab_type": "code",
        "outputId": "db3ce6b6-b2c4-46d8-e36c-0dc1b713de34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Build vocabulary mappings\n",
        "\n",
        "# Zero is used for padding in Keras, prevent using it for a normal word.\n",
        "# Also reserve an index for out-of-vocabulary items.\n",
        "vocabulary={\n",
        "    \"<PAD>\": 0,\n",
        "    \"<OOV>\": 1\n",
        "}\n",
        "\n",
        "for word in words: # These are words from the word2vec model\n",
        "    vocabulary.setdefault(word, len(vocabulary))\n",
        "\n",
        "print(\"Words in vocabulary:\",len(vocabulary))\n",
        "inv_vocabulary = { value: key for key, value in vocabulary.items() } # invert the dictionary\n",
        "\n",
        "\n",
        "# Embedding matrix\n",
        "def load_pretrained_embeddings(vocab, embedding_model):\n",
        "    \"\"\" vocab: vocabulary from our data vectorizer, embedding_model: model loaded with gensim \"\"\"\n",
        "    pretrained_embeddings = numpy.random.uniform(low=-0.05, high=0.05, size=(len(vocab)-1,embedding_model.vectors.shape[1]))\n",
        "    pretrained_embeddings = numpy.vstack((numpy.zeros(shape=(1,embedding_model.vectors.shape[1])), pretrained_embeddings))\n",
        "    found=0\n",
        "    for word,idx in vocab.items():\n",
        "        if word in embedding_model.vocab:\n",
        "            pretrained_embeddings[idx]=embedding_model.get_vector(word)\n",
        "            found+=1\n",
        "            \n",
        "    print(\"Found pretrained vectors for {found} words.\".format(found=found))\n",
        "    return pretrained_embeddings\n",
        "\n",
        "pretrained=load_pretrained_embeddings(vocabulary, vector_model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words in vocabulary: 50002\n",
            "Found pretrained vectors for 50000 words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGaojUBhbyX2",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M9Ox5_ObyX3",
        "colab_type": "code",
        "outputId": "685590e1-8e2c-428e-ba40-6bd535b93743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "#Labels\n",
        "from pprint import pprint\n",
        "\n",
        "not_letter = re.compile(r'[^a-zA-Z]')\n",
        "# Label mappings\n",
        "# 1) gather a set of unique labels\n",
        "label_set = set()\n",
        "for sentence_labels in train_labels: #loops over sentences \n",
        "    #print(sentence_labels)\n",
        "    for label in sentence_labels: #loops over labels in one sentence\n",
        "       # match = not_letter.match(label)\n",
        "        #if match or label== 'O':\n",
        "        #    break\n",
        "        #else:    \n",
        "        label_set.add(label)\n",
        "\n",
        "# 2) index these\n",
        "label_map = {}\n",
        "for index, label in enumerate(label_set):\n",
        "    label_map[label]=index\n",
        "    \n",
        "pprint(label_map)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-CARDINAL': 35,\n",
            " 'B-DATE': 6,\n",
            " 'B-EVENT': 20,\n",
            " 'B-FAC': 12,\n",
            " 'B-GPE': 25,\n",
            " 'B-LANGUAGE': 14,\n",
            " 'B-LAW': 36,\n",
            " 'B-LOC': 34,\n",
            " 'B-MONEY': 28,\n",
            " 'B-NORP': 30,\n",
            " 'B-ORDINAL': 32,\n",
            " 'B-ORG': 1,\n",
            " 'B-PERCENT': 23,\n",
            " 'B-PERSON': 11,\n",
            " 'B-PRODUCT': 9,\n",
            " 'B-QUANTITY': 15,\n",
            " 'B-TIME': 8,\n",
            " 'B-WORK_OF_ART': 16,\n",
            " 'I-CARDINAL': 26,\n",
            " 'I-DATE': 22,\n",
            " 'I-EVENT': 21,\n",
            " 'I-FAC': 2,\n",
            " 'I-GPE': 5,\n",
            " 'I-LANGUAGE': 3,\n",
            " 'I-LAW': 7,\n",
            " 'I-LOC': 27,\n",
            " 'I-MONEY': 31,\n",
            " 'I-NORP': 18,\n",
            " 'I-ORDINAL': 17,\n",
            " 'I-ORG': 33,\n",
            " 'I-PERCENT': 4,\n",
            " 'I-PERSON': 19,\n",
            " 'I-PRODUCT': 29,\n",
            " 'I-QUANTITY': 13,\n",
            " 'I-TIME': 24,\n",
            " 'I-WORK_OF_ART': 10,\n",
            " 'O': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8k8DshceEaI",
        "colab_type": "code",
        "outputId": "83d1116e-e3ea-418a-94a2-f922505b0561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vectorize the labels\n",
        "def label_vectorizer(train_labels,label_map):\n",
        "    vectorized_labels = []\n",
        "    for label in train_labels:\n",
        "        vectorized_example_label = []\n",
        "        for token in label:\n",
        "            if token in label_map:\n",
        "                vectorized_example_label.append(label_map[token])\n",
        "        vectorized_labels.append(vectorized_example_label)\n",
        "    vectorized_labels = numpy.array(vectorized_labels)\n",
        "    return vectorized_labels\n",
        "        \n",
        "\n",
        "vectorized_labels = label_vectorizer(train_labels,label_map)\n",
        "validation_vectorized_labels = label_vectorizer(dev_labels,label_map)\n",
        "\n",
        "pprint(vectorized_labels[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUtqLdCMPf3X",
        "colab_type": "code",
        "outputId": "23cad5d5-d2f9-4abb-ff09-f06096cc00cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## vectorization of the texts\n",
        "def text_vectorizer(vocab, train_texts):\n",
        "    vectorized_data = [] # turn text into numbers based on our vocabulary mapping\n",
        "    sentence_lengths = [] # Number of tokens in each sentence\n",
        "    \n",
        "    for i, one_example in enumerate(train_texts):\n",
        "        vectorized_example = []\n",
        "        for word in one_example:\n",
        "            vectorized_example.append(vocab.get(word, 1)) # 1 is our index for out-of-vocabulary tokens\n",
        "\n",
        "        vectorized_data.append(vectorized_example)     \n",
        "        sentence_lengths.append(len(one_example))\n",
        "        \n",
        "    vectorized_data = numpy.array(vectorized_data) # turn python list into numpy array\n",
        "    \n",
        "    return vectorized_data, sentence_lengths\n",
        "\n",
        "vectorized_data, lengths=text_vectorizer(vocabulary, train_texts)\n",
        "validation_vectorized_data, validation_lengths=text_vectorizer(vocabulary, dev_texts)\n",
        "\n",
        "pprint(train_texts[0])\n",
        "pprint(vectorized_data[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sharon', 'Repudiates', 'the', 'Road', 'Map']\n",
            "[8346, 1, 3, 1685, 8936]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e6FH5F1QGrq",
        "colab_type": "code",
        "outputId": "c78c1034-19eb-4498-c741-d49cf519514c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "# padding for tensor\n",
        "import tensorflow as tf\n",
        "### Only needed for me, not to block the whole GPU, you don't need this stuff\n",
        "#from keras.backend.tensorflow_backend import set_session\n",
        "#config = tf.ConfigProto()\n",
        "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "#set_session(tf.Session(config=config))\n",
        "### ---end of weird stuff\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "print(\"Old shape:\", vectorized_data.shape)\n",
        "vectorized_data_padded=pad_sequences(vectorized_data, padding='pre', maxlen=max(lengths))\n",
        "print(\"New shape:\", vectorized_data_padded.shape)\n",
        "print(\"First example:\")\n",
        "print( vectorized_data_padded[0])\n",
        "# Even with the sparse output format, the shape has to be similar to the one-hot encoding\n",
        "vectorized_labels_padded=numpy.expand_dims(pad_sequences(vectorized_labels, padding='pre', maxlen=max(lengths)), -1)\n",
        "print(\"Padded labels shape:\", vectorized_labels_padded.shape)\n",
        "pprint(label_map)\n",
        "print(\"First example labels:\")\n",
        "pprint(vectorized_labels_padded[0])\n",
        "\n",
        "weights = numpy.copy(vectorized_data_padded)\n",
        "weights[weights > 0] = 1\n",
        "print(\"First weight vector:\")\n",
        "print( weights[0])\n",
        "\n",
        "# Same stuff for the validation data\n",
        "validation_vectorized_data_padded=pad_sequences(validation_vectorized_data, padding='pre', maxlen=max(lengths))\n",
        "validation_vectorized_labels_padded=numpy.expand_dims(pad_sequences(validation_vectorized_labels, padding='pre',maxlen=max(lengths)), -1)\n",
        "validation_weights = numpy.copy(validation_vectorized_data_padded)\n",
        "validation_weights[validation_weights > 0] = 1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Old shape: (30000,)\n",
            "New shape: (30000, 17040)\n",
            "First example:\n",
            "[   0    0    0 ...    3 1685 8936]\n",
            "Padded labels shape: (30000, 17040, 1)\n",
            "{'B-CARDINAL': 35,\n",
            " 'B-DATE': 6,\n",
            " 'B-EVENT': 20,\n",
            " 'B-FAC': 12,\n",
            " 'B-GPE': 25,\n",
            " 'B-LANGUAGE': 14,\n",
            " 'B-LAW': 36,\n",
            " 'B-LOC': 34,\n",
            " 'B-MONEY': 28,\n",
            " 'B-NORP': 30,\n",
            " 'B-ORDINAL': 32,\n",
            " 'B-ORG': 1,\n",
            " 'B-PERCENT': 23,\n",
            " 'B-PERSON': 11,\n",
            " 'B-PRODUCT': 9,\n",
            " 'B-QUANTITY': 15,\n",
            " 'B-TIME': 8,\n",
            " 'B-WORK_OF_ART': 16,\n",
            " 'I-CARDINAL': 26,\n",
            " 'I-DATE': 22,\n",
            " 'I-EVENT': 21,\n",
            " 'I-FAC': 2,\n",
            " 'I-GPE': 5,\n",
            " 'I-LANGUAGE': 3,\n",
            " 'I-LAW': 7,\n",
            " 'I-LOC': 27,\n",
            " 'I-MONEY': 31,\n",
            " 'I-NORP': 18,\n",
            " 'I-ORDINAL': 17,\n",
            " 'I-ORG': 33,\n",
            " 'I-PERCENT': 4,\n",
            " 'I-PERSON': 19,\n",
            " 'I-PRODUCT': 29,\n",
            " 'I-QUANTITY': 13,\n",
            " 'I-TIME': 24,\n",
            " 'I-WORK_OF_ART': 10,\n",
            " 'O': 0}\n",
            "First example labels:\n",
            "array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       ...,\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32)\n",
            "First weight vector:\n",
            "[0 0 0 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhAOVAbBTRAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation function\n",
        "import keras\n",
        "\n",
        "def _convert_to_entities(input_sequence):\n",
        "    \"\"\"\n",
        "    Reads a sequence of tags and converts them into a set of entities.\n",
        "    \"\"\"\n",
        "    entities = []\n",
        "    current_entity = []\n",
        "    previous_tag = label_map['O']\n",
        "    for i, tag in enumerate(input_sequence):\n",
        "        if tag != previous_tag and tag != label_map['O']: # New entity starts\n",
        "            if len(current_entity) > 0:\n",
        "                entities.append(current_entity)\n",
        "                current_entity = []\n",
        "            current_entity.append((tag, i))\n",
        "        elif tag == label_map['O']: # Entity has ended\n",
        "            if len(current_entity) > 0:\n",
        "                entities.append(current_entity)\n",
        "                current_entity = []\n",
        "        elif tag == previous_tag: # Current entity continues\n",
        "            current_entity.append((tag, i))\n",
        "        previous_tag = tag\n",
        "    \n",
        "    # Add the last entity to our entity list if the sentences ends with an entity\n",
        "    if len(current_entity) > 0:\n",
        "        entities.append(current_entity)\n",
        "    \n",
        "    entity_offsets = set()\n",
        "    \n",
        "    for e in entities:\n",
        "        entity_offsets.add((e[0][0], e[0][1], e[-1][1]+1))\n",
        "    return entity_offsets\n",
        "\n",
        "def _entity_level_PRF(predictions, gold, lengths):\n",
        "    pred_entities = [_convert_to_entities(labels[:lengths[i]]) for i, labels in enumerate(predictions)]\n",
        "    gold_entities = [_convert_to_entities(labels[:lengths[i], 0]) for i, labels in enumerate(gold)]\n",
        "    \n",
        "    tp = sum([len(pe.intersection(gold_entities[i])) for i, pe in enumerate(pred_entities)])\n",
        "    pred_count = sum([len(e) for e in pred_entities])\n",
        "    \n",
        "    try:\n",
        "        precision = tp / pred_count # tp / (tp+np)\n",
        "        recall = tp / sum([len(e) for e in gold_entities])\n",
        "        fscore = 2 * precision * recall / (precision + recall)\n",
        "    except Exception as e:\n",
        "        precision, recall, fscore = 0.0, 0.0, 0.0\n",
        "    print('\\nPrecision/Recall/F-score: %s / %s / %s' % (precision, recall, fscore))\n",
        "    return precision, recall, fscore             \n",
        "\n",
        "def evaluate(predictions, gold, lengths):\n",
        "    precision, recall, fscore = _entity_level_PRF(predictions, gold, lengths)\n",
        "    return precision, recall, fscore\n",
        "\n",
        "class EvaluateEntities(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.precision = []\n",
        "        self.recall = []\n",
        "        self.fscore = []\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        pred = numpy.argmax(self.model.predict(validation_vectorized_data_padded), axis=-1)\n",
        "        evaluation_parameters=evaluate(pred, validation_vectorized_labels_padded, validation_lengths)\n",
        "        self.precision.append(evaluation_parameters[0])\n",
        "        self.recall.append(evaluation_parameters[1])\n",
        "        self.fscore.append(evaluation_parameters[2])\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1ydCexfTg5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 1\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Embedding, Activation, TimeDistributed\n",
        "from keras.optimizers import SGD, Adam, Adamax, Adadelta, Adagrad, Nadam \n",
        "\n",
        "example_count, sequence_len = vectorized_data_padded.shape\n",
        "class_count = len(label_set)\n",
        "hidden_size = 50\n",
        "\n",
        "vector_size= pretrained.shape[1]\n",
        "\n",
        "def build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained):\n",
        "    inp=Input(shape=(sequence_len,))\n",
        "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=True, trainable=False, weights=[pretrained])(inp)\n",
        "    hidden = TimeDistributed(Dense(hidden_size, activation=\"relu\"))(embeddings) # We change this activation function\n",
        "    outp = TimeDistributed(Dense(class_count, activation=\"softmax\"))(hidden)\n",
        "    return Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "model = build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oUO3GLfTrl3",
        "colab_type": "code",
        "outputId": "4e745f2f-de98-4fdc-ba9d-cd72526c7cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 17040)             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 17040, 300)        15000600  \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 17040, 50)         15050     \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 17040, 37)         1887      \n",
            "=================================================================\n",
            "Total params: 15,017,537\n",
            "Trainable params: 16,937\n",
            "Non-trainable params: 15,000,600\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIPQrLXUVrWr",
        "colab_type": "code",
        "outputId": "9027d467-a21b-4de9-97d7-58b16dbd1960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# train the model 1\n",
        "optimizer=Adam(lr=0.05) # define the learning rate\n",
        "model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
        "evaluation_function=EvaluateEntities()\n",
        "\n",
        "# train\n",
        "vanilla_hist=model.fit(vectorized_data_padded,vectorized_labels_padded, sample_weight=weights, batch_size=100,verbose=2,epochs=10, callbacks=[evaluation_function])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " - 105s - loss: 3.1306e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.6687898089171974 / 0.09098786828422877 / 0.16018306636155605\n",
            "Epoch 2/10\n",
            " - 105s - loss: 3.2008e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.4003673094582185 / 0.3778162911611785 / 0.388765046812305\n",
            "Epoch 3/10\n",
            " - 105s - loss: 3.0815e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.5641592920353983 / 0.22097053726169844 / 0.3175591531755915\n",
            "Epoch 4/10\n",
            " - 105s - loss: 3.1239e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.40653357531760437 / 0.3882149046793761 / 0.3971631205673759\n",
            "Epoch 5/10\n",
            " - 105s - loss: 3.0803e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.38693877551020406 / 0.41074523396880414 / 0.3984867591424968\n",
            "Epoch 6/10\n",
            " - 105s - loss: 3.1050e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.3672612801678909 / 0.30329289428076256 / 0.33222591362126247\n",
            "Epoch 7/10\n",
            " - 105s - loss: 3.0821e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.5287187039764359 / 0.31109185441941073 / 0.3917075831969449\n",
            "Epoch 8/10\n",
            " - 105s - loss: 3.0615e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.4038623005877414 / 0.4168110918544194 / 0.4102345415778252\n",
            "Epoch 9/10\n",
            " - 105s - loss: 3.0937e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.4254545454545455 / 0.4055459272097054 / 0.4152617568766638\n",
            "Epoch 10/10\n",
            " - 105s - loss: 3.0877e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.5603448275862069 / 0.22530329289428075 / 0.3213844252163164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bah0URSVV5GP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "21e2c8d0-0cc8-4354-a43c-af37154fcd90"
      },
      "source": [
        "# plot the f scores\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(fscores):\n",
        "    print(\"History:\", fscores)\n",
        "    print(\"Highest f-score:\", max(fscores))\n",
        "    plt.plot(fscores)\n",
        "    plt.legend(loc='lower center', borderaxespad=0.)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(evaluation_function.fscore)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "History: [0.40585562847046946, 0.41901245962159667, 0.41963872163038446, 0.40605773781353527, 0.4121050289274588, 0.3953279424977538, 0.41286113699906796, 0.3550239234449761, 0.4021210782147592, 0.38383838383838387]\n",
            "Highest f-score: 0.41963872163038446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKpy2xq0NeSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 2\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Embedding, Activation, TimeDistributed\n",
        "from keras.optimizers import SGD, Adam, Adamax, Adadelta, Adagrad, Nadam \n",
        "\n",
        "example_count, sequence_len = vectorized_data_padded.shape\n",
        "class_count = len(label_set)\n",
        "hidden_size = 50\n",
        "\n",
        "vector_size= pretrained.shape[1]\n",
        "\n",
        "def build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained):\n",
        "    inp=Input(shape=(sequence_len,))\n",
        "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=True, trainable=False, weights=[pretrained])(inp)\n",
        "    hidden = TimeDistributed(Dense(hidden_size, activation=\"sigmoid\"))(embeddings) # We change this activation function\n",
        "    outp = TimeDistributed(Dense(class_count, activation=\"softmax\"))(hidden)\n",
        "    return Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "model2 = build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTYjLB28KfUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "cfe99d92-ab2e-40b2-aeae-42034687563d"
      },
      "source": [
        "# train the model 2\n",
        "optimizer=Adamax(lr=0.01) # define the learning rate\n",
        "model2.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
        "evaluation_function=EvaluateEntities()\n",
        "\n",
        "# train\n",
        "vanilla_hist=model2.fit(vectorized_data_padded,vectorized_labels_padded, sample_weight=weights, batch_size=100,verbose=2,epochs=10, callbacks=[evaluation_function])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " - 106s - loss: 3.0307e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.43915827996340345 / 0.41594454072790293 / 0.4272363150867824\n",
            "Epoch 2/10\n",
            " - 106s - loss: 3.0239e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.4319695528068506 / 0.3934142114384749 / 0.4117913832199547\n",
            "Epoch 3/10\n",
            " - 105s - loss: 3.0200e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.43486410496719774 / 0.4020797227036395 / 0.41782980639351647\n",
            "Epoch 4/10\n",
            " - 105s - loss: 3.0120e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.4317521781219748 / 0.38648180242634317 / 0.407864654778235\n",
            "Epoch 5/10\n",
            " - 105s - loss: 3.0088e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.4323529411764706 / 0.3821490467937608 / 0.4057037718491261\n",
            "Epoch 6/10\n",
            " - 105s - loss: 3.0081e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.43304843304843305 / 0.3951473136915078 / 0.4132306298142275\n",
            "Epoch 7/10\n",
            " - 105s - loss: 3.0092e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.4304889741131352 / 0.38908145580589254 / 0.4087391898042786\n",
            "Epoch 8/10\n",
            " - 105s - loss: 2.9963e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.4327433628318584 / 0.4237435008665511 / 0.4281961471103327\n",
            "Epoch 9/10\n",
            " - 105s - loss: 2.9969e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.43519394512771997 / 0.3986135181975737 / 0.4161013116236997\n",
            "Epoch 10/10\n",
            " - 106s - loss: 2.9980e-04\n",
            "\n",
            "Precision/Recall/F-score: 0.43452958292919497 / 0.3882149046793761 / 0.41006864988558356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIm0vXkjKqYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "06e0ea0f-3d41-43f1-99c9-97b82558f559"
      },
      "source": [
        "# plot the f scores\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(fscores):\n",
        "    print(\"History:\", fscores)\n",
        "    print(\"Highest f-score:\", max(fscores))\n",
        "    plt.plot(fscores)\n",
        "    plt.legend(loc='lower center', borderaxespad=0.)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(evaluation_function.fscore)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "History: [0.16018306636155605, 0.388765046812305, 0.3175591531755915, 0.3971631205673759, 0.3984867591424968, 0.33222591362126247, 0.3917075831969449, 0.4102345415778252, 0.4152617568766638, 0.3213844252163164]\n",
            "Highest f-score: 0.4152617568766638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVS-GKkQUpue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 3\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Embedding, Activation, TimeDistributed\n",
        "from keras.optimizers import SGD, Adam, Adamax, Adadelta, Adagrad, Nadam \n",
        "\n",
        "example_count, sequence_len = vectorized_data_padded.shape\n",
        "class_count = len(label_set)\n",
        "hidden_size = 50\n",
        "\n",
        "vector_size= pretrained.shape[1]\n",
        "\n",
        "def build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained):\n",
        "    inp=Input(shape=(sequence_len,))\n",
        "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=True, trainable=False, weights=[pretrained])(inp)\n",
        "    hidden = TimeDistributed(Dense(hidden_size, activation=\"sigmoid\"))(embeddings) # We change this activation function\n",
        "    outp = TimeDistributed(Dense(class_count, activation=\"softmax\"))(hidden)\n",
        "    return Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "model3 = build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuWSrGPVUw9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "5b4d62e0-b936-45cb-c2f9-0c7b940e816f"
      },
      "source": [
        "# train the model 3\n",
        "optimizer=Adadelta(lr=0.01) # define the learning rate\n",
        "model3.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
        "evaluation_function=EvaluateEntities()\n",
        "\n",
        "# train\n",
        "vanilla_hist=model3.fit(vectorized_data_padded,vectorized_labels_padded, sample_weight=weights, batch_size=100,verbose=2,epochs=10, callbacks=[evaluation_function])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " - 106s - loss: 0.0052\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
            "Epoch 2/10\n",
            " - 106s - loss: 0.0051\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
            "Epoch 3/10\n",
            " - 106s - loss: 0.0051\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
            "Epoch 4/10\n",
            " - 106s - loss: 0.0050\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
            "Epoch 5/10\n",
            " - 105s - loss: 0.0050\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
            "Epoch 6/10\n",
            " - 105s - loss: 0.0049\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
            "Epoch 7/10\n",
            " - 105s - loss: 0.0049\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
            "Epoch 8/10\n",
            " - 105s - loss: 0.0048\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
            "Epoch 9/10\n",
            " - 105s - loss: 0.0048\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n",
            "Epoch 10/10\n",
            " - 105s - loss: 0.0047\n",
            "\n",
            "Precision/Recall/F-score: 0.0 / 0.0 / 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cwMwwo9-MPv4"
      },
      "source": [
        "## 1.2 Expand context\n",
        "\n",
        "Modify your network in such way that it is able to utilize the surrounding context of the word. This can be done for instance with a convolutional or recurrent layer. Analyze different neural network architectures and hyperparameters. How does utilizing the surrounding context influence the predictions?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw9pXRewbyX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#expanding to RNN model with context\n",
        "\n",
        "from keras.layers import LSTM\n",
        "\n",
        "example_count, sequence_len = vectorized_data_padded.shape\n",
        "class_count = len(label_set)\n",
        "rnn_size = 100\n",
        "\n",
        "vector_size= pretrained.shape[1]\n",
        "\n",
        "def build_rnn_model(example_count, sequence_len, class_count, rnn_size, vocabulary, vector_size, pretrained):\n",
        "    inp=Input(shape=(sequence_len,))\n",
        "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=False, trainable=False, weights=[pretrained])(inp)\n",
        "    rnn = LSTM(rnn_size, activation='relu', return_sequences=True)(embeddings)\n",
        "    outp=Dense(class_count, activation=\"softmax\")(rnn)\n",
        "    return Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "rnn_model = build_rnn_model(example_count, sequence_len, class_count, rnn_size, vocabulary, vector_size, pretrained)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPP-kwoNXUMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIal9meVXnN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "optimizer=Adam(lr=0.01) # define the learning rate\n",
        "rnn_model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
        "\n",
        "evaluation_function=EvaluateEntities()\n",
        "\n",
        "# train\n",
        "rnn_hist=rnn_model.fit(vectorized_data_padded,vectorized_labels_padded, sample_weight=weights, batch_size=100,verbose=2,epochs=10, callbacks=[evaluation_function])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRKNs4t8X3Ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plot_history(evaluation_function.fscore)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sCo0xF5kMMbH"
      },
      "source": [
        "## 2.1 Use deep contextual representations\n",
        "\n",
        "Use deep contextual representations. Fine-tune the embeddings with different hyperparameters. Try different models (e.g. cased and uncased, multilingual BERT). Report your results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgSYNcerMI9R"
      },
      "source": [
        "## 2.2 Error analysis\n",
        "\n",
        "Select one model from each of the previous milestones (three models in total). Look at the entities these models predict. Analyze the errors made. Are there any patterns? How do the errors one model makes differ from those made by another?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aRDxKgLSL_uf"
      },
      "source": [
        "## 3.1 Predictions on unannotated text\n",
        "\n",
        "Use the three models selected in milestone 2.2 to do predictions on the sampled wikipedia text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wlG6ZWkIL-HY"
      },
      "source": [
        "## 3.2 Statistically analyze the results\n",
        "\n",
        "Statistically analyze (i.e. count the number of instances) and compare the predictions. You can, for example, analyze if some models tend to predict more entities starting with a capital letter, or if some models predict more entities for some specific classes than others."
      ]
    }
  ]
}