Milestone 1:

- cleaned the data, f.ex. nested items that created over long sentence items (SV)
- Trained models with an evaluation of the f score on entity level
- Experimented with different activation functions, learning rates and optimizers
- Most models did not perform well, however Adadelta with sigmoid as an activation and a learning rate of 0.07 managed to produce a model with f score of 0.9 (noteSV: I got all zeros with this using the clean data??)
- Expanded the model with an LSTM
- trained Bidirectional LSTM (SV)

Milestone 2:
- Tried to use cased Bert, had some problems with input data
- Found a way to show predictions using saved models

Milestone 3:
-Unfortunately, nothing yet

Issues: 
- Colab was crashing and our computers, too
- On the day of the deadline, we identified a problem with the data that made everything extremely difficult. Our longest sentence was around 17000 words long which turned out to be a mistake and the reason all our available tools were crashing all the time
